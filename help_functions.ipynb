{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a74bb121",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PIL import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62d6895f",
   "metadata": {},
   "source": [
    "# receiving data functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c525d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create four data frames of the relavant data\n",
    "def get_data():\n",
    "    train = pd.read_csv(\"./data/food_train.csv\")\n",
    "    test = pd.read_csv(\"./data/food_test.csv\")\n",
    "    nutrients = pd.read_csv(\"./data/nutrients.csv\")\n",
    "    food_nutrients = pd.read_csv(\"./data/food_nutrients.csv\")\n",
    "    return(train, test,food_nutrients, nutrients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "216af570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge food table with nutrients table to get for each food his nutrients\n",
    "def merge_train_food_nutirents_nutrients():\n",
    "    train, test, food_nutrients, nutrients = get_data()\n",
    "    food_nutrients = food_nutrients[food_nutrients[\"amount\"]>0]\n",
    "    train_food_nutrients = pd.merge(train,food_nutrients,on='idx')\n",
    "    output = pd.merge(train_food_nutrients, nutrients, on = \"nutrient_id\")\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9df1496b",
   "metadata": {},
   "source": [
    "# probability functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a52e9558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return for each category the probability of a specific word to appear on foods parameter(such as: \"brand\", \"description\")\n",
    "#that belongs to this category\n",
    "# return a data frame that category column includes category names, and percentage_words column includes the precentage of \n",
    "# the word(that it is given to the function as an argument) to appear in this category.\n",
    "def common_words_category(word, col):\n",
    "    train, test, food_nutrients, nutrients = get_data()\n",
    "    train['words']= train[col].apply(lambda x: 1 if word in str(x) else 0)\n",
    "    #train['words']= train['description'].apply(lambda x: 1 if word in x else 0)\n",
    "    tmp1 = train.groupby(\"category\", as_index = False).sum()[[\"category\", \"words\"]]\n",
    "    tmp2 = train.groupby(\"category\", as_index = False).count()\n",
    "    output =pd.merge(tmp1,tmp2, on = \"category\")[[\"category\", \"words_x\", \"words_y\"]]\n",
    "    output[\"percentage_words\"] = round(100*output[\"words_x\"]/output[\"words_y\"], 2)\n",
    "    return(output[[\"category\", \"percentage_words\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231f7105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_common_words(number_of_common_words,df_common_words, column, func, col_func_name , other_func,col_other_func_name ,words_to_check = 50):\n",
    "    categories= [\"cakes_cupcakes_snack_cakes\", \"candy\", \"chips_pretzels_snacks\", \"chocolate\" , \"cookies_biscuits\", \"popcorn_peanuts_seeds_related_snacks\"]\n",
    "    out_table= pd.DataFrame({\"word\":[], \"percentage\":[],  \"percentage_2\":[], \"category\":[]})\n",
    "    for i in range(len(categories)):\n",
    "        cat = categories[i]\n",
    "        tmp_table= get_top_common_words_of_cat(number_of_common_words,df_common_words, column, cat, func, col_func_name,other_func, col_other_func_name, words_to_check)\n",
    "        out_table = pd.concat([out_table, tmp_table], axis=0)\n",
    "    out_table.drop('index', inplace=True, axis=1)\n",
    "    for i in range(len(categories)):\n",
    "        cat = categories[i]\n",
    "        tmp_table= get_top_common_words_of_cat(number_of_common_words,df_common_words, column, cat, other_func, col_other_func_name,func, col_func_name, words_to_check, True)\n",
    "        out_table = pd.concat([out_table, tmp_table], axis=0)\n",
    "    #out_table.drop('index', inplace=True, axis=1)  \n",
    "    return(out_table.reset_index(drop= True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "86dc6a30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns for each catgeory the probabilty that a food belongs to it,\n",
    "# given that the word in the  arguments of the function appears in this food's parameter(=col)\n",
    "# return a data frame that category column includes category names, and category_percentage column includes the precentage of \n",
    "# the word(that it is given to the function as an argument) to appear in this category.\n",
    "def category_if_word(word,col):\n",
    "    #bayes method\n",
    "    train, test, food_nutrients, nutrients = get_data()\n",
    "    #train['words']= train['description'].apply(lambda x: 1 if word in x else 0)\n",
    "    train['words']= train[col].apply(lambda x: 1 if word in str(x) else 0)\n",
    "    n_words =train[\"words\"].sum()\n",
    "    n = len(train)\n",
    "    tmp1 = train.groupby(\"category\", as_index = False).sum()[[\"category\", \"words\"]]\n",
    "    cat_table = train.groupby(\"category\", as_index = False).count()\n",
    "    word_if_cat =pd.merge(tmp1,cat_table, on = \"category\")[[\"category\", \"words_x\", \"words_y\"]]\n",
    "    word_if_cat[\"percentage_words\"] = word_if_cat[\"words_x\"]/word_if_cat[\"words_y\"]\n",
    "    word_if_cat = word_if_cat[[\"category\", \"percentage_words\"]]\n",
    "    cat_table[\"words\"] = cat_table[\"words\"]/n\n",
    "    out = pd.merge(word_if_cat,cat_table, on=\"category\")\n",
    "    out[\"category_percentage\"] = round(100*out[\"percentage_words\"]*out[\"words\"]/(n_words/n), 2)\n",
    "    return(out[[\"category\", \"category_percentage\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92817719",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_common_words_of_cat(number_of_common_words,df_common_words, column,cat, func, col_func_name , other_func,col_other_func_name ,words_to_check = 50,flip =False):\n",
    "    min_val = 0\n",
    "    min_word =None\n",
    "    table_sum = pd.DataFrame({\"word\":[], \"percentage\":[],  \"percentage_2\":[]})\n",
    "    i = 0\n",
    "    for word in df_common_words['Name']:\n",
    "        table= func(word,column)\n",
    "        filter_table= table[table['category']==cat].reset_index()\n",
    "        table_sum.loc[len(table_sum.index)] = [word, filter_table[col_func_name][0], 0]\n",
    "        if(i>=words_to_check):\n",
    "            break\n",
    "        i+=1\n",
    "    table_sum.sort_values(['percentage'], ascending = False, inplace = True)\n",
    "    out_table = table_sum.head(number_of_common_words).reset_index()\n",
    "    for j in range(len(out_table)):\n",
    "        word= out_table['word'][j]\n",
    "        table= other_func(word,column)\n",
    "        filter_table= table[table['category']==cat].reset_index()\n",
    "        out_table.at[j, \"percentage_2\"] = filter_table[col_other_func_name][0]\n",
    "    out_table['category'] = cat\n",
    "    if flip:\n",
    "        return(pd.DataFrame({\"word\":out_table['word'], \"percentage\":out_table[\"percentage_2\"],  \"percentage_2\":out_table[\"percentage\"], 'category': out_table['category']}))\n",
    "    return(out_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e8b2b0",
   "metadata": {},
   "source": [
    "# brand functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "080043b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns brands that make  at least num_of_foods for exactly num_of_categories\n",
    "def get_expert_brands(num_of_foods, num_of_categories):\n",
    "    train, test, food_nutrients, nutrients = get_data()\n",
    "    #brand_agg = train.groupby([\"brand\"], as_index= False).count().sort_values([\"brand\", \"idx\"], ascending=False)[[\"brand\", \"idx\"]]\n",
    "    brand_agg = train.groupby([\"brand\"], as_index= False).count()[[\"brand\", \"idx\"]]\n",
    "    brand_agg.rename(columns = {'idx':'num_of_foods'}, inplace = True)\n",
    "    #brand_cat_agg = train.groupby([\"brand\", \"category\"], as_index= False).count().sort_values([\"brand\", \"idx\"], ascending=False)\n",
    "    #brand_category = brand_cat_agg.groupby([\"brand\"])[\"category\"].count().sort_values()\n",
    "    brand_cat_agg = train.groupby([\"brand\", \"category\"], as_index= False).count()\n",
    "    brand_category = brand_cat_agg.groupby([\"brand\"])[\"category\"].count()\n",
    "    brand_category_merged = pd.merge(brand_agg, brand_category, on= \"brand\")\n",
    "    brand_category_merged.rename(columns = {'category':'num_of_categories'}, inplace = True)\n",
    "    output = brand_category_merged[(brand_category_merged[\"num_of_foods\"]> num_of_foods) & (brand_category_merged[\"num_of_categories\"]==num_of_categories)]\n",
    "    output = output.sort_values([\"num_of_foods\"], ascending=False)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a2412945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all the brands that produce at least num_of_foods products and all of their products are belongs to \n",
    "# one food category.\n",
    "def get_brands_expert_one_category(num_of_foods):\n",
    "    train, test, food_nutrients, nutrients = get_data()\n",
    "    brand_agg = train.groupby([\"brand\"], as_index= False).agg({'category': ['nunique']})\n",
    "    brand_agg.columns = [\"brand\", \"num_categories\"]\n",
    "    brand_agg_filter = brand_agg[brand_agg[\"num_categories\"] == 1]\n",
    "    brand_cat_agg = train.groupby([\"brand\", \"category\"], as_index= False).count()\n",
    "    brand_category_merged = pd.merge(brand_agg_filter, brand_cat_agg, on= \"brand\")[['brand','category', 'idx']]\n",
    "    brand_category_merged.rename(columns = {'idx':'num_of_foods'}, inplace = True)\n",
    "    brand_category_merged_filter = brand_category_merged[brand_category_merged['num_of_foods']>= num_of_foods]\n",
    "    return(brand_category_merged_filter.sort_values(['num_of_foods'], ascending=False).reset_index(drop =True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b240d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns for expert brands their category of experty\n",
    "# expert brand = brand that makes at least num_of_food for a specific category and does not make foods that belongs to other\n",
    "# categories\n",
    "def expert_brands_category(num_of_foods):\n",
    "    expert_brands = get_expert_brands(num_of_foods,1)\n",
    "    train, test, food_nutrients, nutrients = get_data()\n",
    "    out = pd.merge(expert_brands, train, on= \"brand\")[[\"brand\", \"num_of_foods\", \"category\", \"num_of_categories\"]]\n",
    "    out = out.groupby([\"brand\", \"num_of_foods\", \"category\"], as_index= False).count()\n",
    "    return(out[[\"brand\", \"num_of_foods\", \"category\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8be96952",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plots a bar plot of all brands that produce at least num_of_foods products and all of their products are belongs to \n",
    "# one food category. (x lables are: brands names, y lbles are: amount of products each brand makes)\n",
    "def plot_expert_brands(num_of_foods):\n",
    "    brand_that_make_products_for_one_cat =expert_brands_category(num_of_foods).sort_values([\"category\", \"num_of_foods\"], ascending= False)\n",
    "    brand_that_make_products_for_one_cat\n",
    "    plt.figure(figsize=(7,7))\n",
    "    ax = sns.barplot(x=\"brand\", y=\"num_of_foods\", hue=\"category\",data=brand_that_make_products_for_one_cat, dodge=False)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(),rotation = 45, horizontalalignment='right')\n",
    "    ax.set_title(f\"brands that make at least {num_of_foods} products for one category and 0 products for other categories\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0e199eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all brands that produce at least 'num_of_foods' products and there is at least one category that\n",
    "# 'precentage' precentageof the products this brand produce is from this category.\n",
    "def get_prob_brands(min_num_of_foods, precentage):\n",
    "    train, test, food_nutrients, nutrients = get_data()\n",
    "    brand_agg = train.groupby([\"brand\"], as_index= False).count()[[\"brand\", \"idx\"]]\n",
    "    brand_agg.rename(columns = {'idx':'num_of_foods'}, inplace = True)\n",
    "    brand_agg = brand_agg[brand_agg['num_of_foods'] >=min_num_of_foods]\n",
    "    brand_cat_agg = train.groupby([\"brand\", \"category\"], as_index= False).count()\n",
    "    #brand_category = brand_cat_agg.groupby([\"brand\"])[\"category\"].count()\n",
    "    brand_category = brand_cat_agg[[ \"brand\", \"category\", \"idx\"]]\n",
    "    brand_category = brand_category.rename(columns = {'idx': 'num_foods_category'}, inplace = False)\n",
    "    brand_category_merged = pd.merge(brand_agg, brand_category, on= \"brand\")\n",
    "    brand_category_merged['precentage'] = round((100*brand_category_merged.num_foods_category/brand_category_merged.num_of_foods),2)\n",
    "    out= brand_category_merged[brand_category_merged.precentage>=precentage][['category', 'brand', 'num_of_foods', 'precentage']]\n",
    "    return(out.sort_values([\"category\", \"precentage\"], ascending= False).reset_index(drop =True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be90c71",
   "metadata": {},
   "source": [
    "# transformation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3da9a590",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  function that deletes non english characters from a string\n",
    "def to_english(words):\n",
    "    output= []\n",
    "    for word in words:\n",
    "        res = re.sub(r'[^a-zA-Z ]', '', word)\n",
    "        if (len(res)>1):\n",
    "            output.append(res)\n",
    "    #print(out)\n",
    "    return(','.join(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d67733c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that gets dictionary of dictionries that the keys of the outr dicto\n",
    "def add_words_to_dict(cat, dic,words):\n",
    "    words_list = words.split(',')\n",
    "    cur_dic = dic[str(cat)]\n",
    "    for word in words_list:\n",
    "        if word in cur_dic:\n",
    "            cur_dic[word] +=1\n",
    "        else:\n",
    "            cur_dic[word]=1\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdb89e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for each category return  words that appears at least n times in this category in a food's parameter(=col)\n",
    "# returns dictionary that it's keys are categories names and its values are the words that fulfill the condition.\n",
    "def find_common_words(words_dict, col, limit,func):\n",
    "    output = {\"cakes_cupcakes_snack_cakes\":[], \"candy\":[], \"chips_pretzels_snacks\":[], \"chocolate\": [], \"cookies_biscuits\":[], \"popcorn_peanuts_seeds_related_snacks\":[]}\n",
    "    for word in words_dict:\n",
    "            table= func(word, col)\n",
    "            for cat in output:\n",
    "                tmp_table= table[table[\"category\"] == cat].reset_index()\n",
    "                if (tmp_table.iloc[0,2]>=limit):\n",
    "                    output[cat].append(word)\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "017e9884",
   "metadata": {},
   "source": [
    "# ingredients functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ded70b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return for each (category, ingredient) the number of foods in this category that use this ingredient to make them.\n",
    "def get_common_ingredients():\n",
    "    train, test, food_nutrients, nutrients = get_data()\n",
    "    output = {\"cakes_cupcakes_snack_cakes\":{}, \"candy\":{}, \"chips_pretzels_snacks\":{}, \"chocolate\": {}, \"cookies_biscuits\":{}, \"popcorn_peanuts_seeds_related_snacks\":{}}\n",
    "    train['modify_ing'] = train['ingredients'].apply(lambda x: to_english(str(x).split(',')))\n",
    "    train.apply(lambda x: add_words_to_dict(x['category'], output, x['modify_ing']), axis =1)\n",
    "    table_list = []\n",
    "    for k in output:\n",
    "        dic = output[k]\n",
    "        tmp = pd.DataFrame.from_dict(dic, orient= 'index').reset_index()\n",
    "        tmp.rename(columns={'index': 'ingredient', 0:'number_of_uses'}, inplace=True)\n",
    "        tmp['category'] = k\n",
    "        table_list.append(tmp)\n",
    "    final_table= table_list[0]\n",
    "    for i in range(1,len(table_list)):\n",
    "        cur_table= table_list[i]\n",
    "        final_table = pd.merge(final_table, cur_table, how='outer', on=['ingredient', 'category', 'number_of_uses'])\n",
    "    final_table = final_table[['category', 'ingredient', 'number_of_uses']]\n",
    "    return(final_table.sort_values(['category', 'number_of_uses'], ascending=False).reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "295ef8ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def intersection_common_ing(num_of_ing):\n",
    "    common_ing_table = get_common_ingredients()\n",
    "    categories = common_ing_table.category.unique()\n",
    "    output= dict()\n",
    "    for category in categories:\n",
    "        tmp_table = common_ing_table[common_ing_table['category'] == category].head(num_of_ing)\n",
    "        output[category] = tmp_table['ingredient'].to_list()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8404e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_in_sentence(words_list, sentence):\n",
    "    for word in words_list:\n",
    "        if word not in sentence:\n",
    "            return 0\n",
    "    return(1)\n",
    "\n",
    "def plot_common_ing(num_of_ing, plot_size=5):\n",
    "    common_ing_dict = intersection_common_ing(num_of_ing)\n",
    "    train, test, food_nutrients, nutrients = get_data()\n",
    "    train['modify_ing'] = train['ingredients'].apply(lambda x: to_english(str(x).split(',')))\n",
    "    n = len(train)\n",
    "    for cat in common_ing_dict:\n",
    "        train[\"exist_\"+cat] = train['modify_ing'].apply(lambda x: check_in_sentence(common_ing_dict[cat], x))\n",
    "        n_words =train[\"exist_\"+cat].sum()\n",
    "        tmp1 = train.groupby(\"category\", as_index = False).sum()[[\"category\", \"exist_\"+cat]]\n",
    "        cat_table = train.groupby(\"category\", as_index = False).count()\n",
    "        word_if_cat =pd.merge(tmp1,cat_table, on = \"category\")[[\"category\", \"exist_\"+cat+\"_x\", \"exist_\"+cat+\"_y\"]]\n",
    "        word_if_cat[\"percentage_words\"] = word_if_cat[\"exist_\"+cat+\"_x\"]/word_if_cat[\"exist_\"+cat+\"_y\"]\n",
    "        word_if_cat = word_if_cat[[\"category\", \"percentage_words\"]]\n",
    "        cat_table[\"exist_\"+cat] = cat_table[\"exist_\"+cat]/n\n",
    "        out = pd.merge(word_if_cat,cat_table, on=\"category\")\n",
    "        out[\"category_percentage\"] = round(100*out[\"percentage_words\"]*out[\"exist_\"+cat]/(n_words/n), 1)\n",
    "        plt.figure()\n",
    "        ax = sns.barplot(x=\"category\", y=\"category_percentage\", data=out)\n",
    "        ax.set_title(f\"{cat} with {num_of_ing} most common ing {common_ing_dict[cat]}\")\n",
    "        ax.set_xticklabels(ax.get_xticklabels(),rotation = 45, horizontalalignment='right')\n",
    "        ax.set_ylim([0,100])\n",
    "        ax.bar_label(ax.containers[0])\n",
    "    return(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1140eb3",
   "metadata": {},
   "source": [
    "# nutrients functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "523cf8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a dictionary that it's keys are categories names and it's values are dictionaries.\n",
    "# in each inner dictionary it's keys are nutrients names and it's values are the number of categories that this nutirent\n",
    "# is not appear on them.\n",
    "# therefore this function  returns got each category the nutirents that at least one of food's category has the nutrient , but\n",
    "# at least one category does not have this nutrient, and we count for this nutrient the number of categories that it is not \n",
    "# appear in them\n",
    "def get_unq_values_cat():\n",
    "    food_nutrient_category = merge_train_food_nutirents_nutrients().groupby([\"category\",\"name\"], as_index = False).mean()[[\"category\",\"name\", \"amount\"]]\n",
    "    category_dict = {fn: dict() for fn in food_nutrient_category.category.unique()}\n",
    "    for cat in food_nutrient_category.category.unique():\n",
    "        unq_values= food_nutrient_category[food_nutrient_category.category == cat].name.unique()\n",
    "        cur_dic = category_dict[cat]\n",
    "        for cat1 in food_nutrient_category.category.unique():\n",
    "            if cat1==cat:\n",
    "                continue\n",
    "            unq_values1= food_nutrient_category[food_nutrient_category.category == cat1].name.unique()   \n",
    "            unq_list = list(set(unq_values) - set(unq_values1))\n",
    "            for v in unq_list:\n",
    "                if v in cur_dic.keys():\n",
    "                    cur_dic[v]+=1\n",
    "                else:\n",
    "                    cur_dic[v]=1\n",
    "    return(category_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab92c213",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns for each category it's n top used nutrients.\n",
    "def get_top_n_nutrients(n):\n",
    "    food_nutrient_category = merge_train_food_nutirents_nutrients().groupby([\"category\",\"name\"], as_index = False).count()[[\"category\",\"name\", \"amount\"]].sort_values([\"category\", \"amount\"], ascending= False)\n",
    "    categories_dic = { \"candy\":{}, \"chips_pretzels_snacks\":{}, \"chocolate\": {}, \"cookies_biscuits\":{}, \"popcorn_peanuts_seeds_related_snacks\":{}}\n",
    "    output =food_nutrient_category[food_nutrient_category[\"category\"]==\"cakes_cupcakes_snack_cakes\"].head(n)\n",
    "    for cat in categories_dic:\n",
    "        tmp_table = food_nutrient_category[food_nutrient_category[\"category\"]==cat].head(n)\n",
    "        output = pd.concat([output, tmp_table], axis=0, join='inner')\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aeb6d9bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return all the products that their ingredients includes all top n used ingredients of at least one category\n",
    "def get_products_with_top_n_nutrient(n):\n",
    "    food_nutrient_category = merge_train_food_nutirents_nutrients()\n",
    "    top_nutrient = get_top_n_nutrients(n)\n",
    "    merge_table =pd.merge(food_nutrient_category,top_nutrient, on = [\"category\", \"name\"]).groupby([\"category\",\"idx\"], as_index = False).count()[[\"category\",\"idx\", \"amount_x\"]]\n",
    "    merge_table.rename(columns = {\"amount_x\":\"amount\"}, inplace = True)\n",
    "    output = merge_table[merge_table[\"amount\"]==n]\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f151b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probabilty_of_product_to_have_top_n_nutrient_of_his_category(n):\n",
    "    # top n nutrient = top n nutrient = n nutrients that appears the most in category\n",
    "    train, test, food_nutrients, nutrients = get_data()\n",
    "    food_nutrient_category = merge_train_food_nutirents_nutrients()\n",
    "    top_nutrient = get_top_n_nutrients(n)\n",
    "    merge_table =pd.merge(food_nutrient_category,top_nutrient, on = [\"category\", \"name\"]).groupby([\"category\",\"idx\"], as_index = False).count()[[\"category\",\"idx\", \"amount_x\"]]\n",
    "    merge_table.rename(columns = {\"amount_x\":\"amount\"}, inplace = True)\n",
    "    p = merge_table[merge_table[\"amount\"]==n]\n",
    "    final_table = pd.DataFrame({\"category\":[\"cakes_cupcakes_snack_cakes\", \"candy\", \"chips_pretzels_snacks\", \"chocolate\",\"cookies_biscuits\", \"popcorn_peanuts_seeds_related_snacks\"],\n",
    "                               \"percentage\":[len(p[p[\"category\"] ==\"cakes_cupcakes_snack_cakes\"])/len(train[train[\"category\"] ==\"cakes_cupcakes_snack_cakes\"]), len(p[p[\"category\"] ==\"candy\"])/len(train[train[\"category\"] ==\"candy\"]),len(p[p[\"category\"] ==\"chips_pretzels_snacks\"])/len(train[train[\"category\"] ==\"chips_pretzels_snacks\"]),len(p[p[\"category\"] ==\"chocolate\"])/len(train[train[\"category\"] ==\"chocolate\"]),len(p[p[\"category\"] ==\"cookies_biscuits\"])/len(train[train[\"category\"] ==\"cookies_biscuits\"]),len(p[p[\"category\"] ==\"popcorn_peanuts_seeds_related_snacks\"])/len(train[train[\"category\"] ==\"popcorn_peanuts_seeds_related_snacks\"])]})\n",
    "                                #final_table = pd.DataFrame({\"candy\":[len(p[p[\"category\"] ==\"candy\"])/len(train[train[\"category\"] ==\"candy\"])]})\n",
    "    final_table['percentage'] = round(100*final_table['percentage'],2)\n",
    "    ax = sns.barplot(x=\"category\", y=\"percentage\", data=final_table)\n",
    "    ax.set_xticklabels(ax.get_xticklabels(),rotation = 45, horizontalalignment='right')\n",
    "    ax.set_title(f\"percentage of product to have {n} top nutrients\")\n",
    "    ax.set_ylim([0,100])\n",
    "    ax.bar_label(ax.containers[0])\n",
    "    return(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f22c700",
   "metadata": {},
   "source": [
    "# Images functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "09f162ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_train_images = \"./images/train/\"\n",
    "path_to_test_images = \"./images/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2fa4df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates table of  that includes for each test image his width and height\n",
    "def test_images_dims(folder_path):\n",
    "    onlyfiles = [f for f in listdir(folder_path) if isfile(join(folder_path, f))]\n",
    "    output= pd.DataFrame({\"image\":[], \"height\": [], \"width\": []})\n",
    "    for file in onlyfiles:\n",
    "        filepath = f\"{folder_path}/{file}\"\n",
    "        img = Image.open(filepath)\n",
    "        width = img.width\n",
    "        height = img.height\n",
    "        img_name = int(file[:-4])\n",
    "        output.loc[len(output)] = [img_name, height, width]\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba37eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates table of  that includes for each train image his width and height\n",
    "def train_images_dims(folder_path):\n",
    "    onlyDirs = [f for f in listdir(folder_path) if not isfile(join(folder_path, f))]\n",
    "    output= pd.DataFrame({\"image\":[], \"height\": [], \"width\": [], \"category\":[]})\n",
    "    for DIR in onlyDirs:\n",
    "        onlyfiles = [f for f in listdir(f\"{folder_path}/{DIR}\") if isfile(join(f\"{folder_path}/{DIR}\", f))]\n",
    "        for file in onlyfiles:\n",
    "            filepath = f\"{folder_path}/{DIR}/{file}\"\n",
    "            img = Image.open(filepath)\n",
    "            width = img.width\n",
    "            height = img.height\n",
    "            img_name = int(file[:-4])\n",
    "            output.loc[len(output)] = [img_name, height, width, DIR]\n",
    "    return(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07af504",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creates histogram plot of the test/train images width/height \n",
    "def plot_img_attribute(type_of_img, atr, train_path=path_to_train_images, test_path=path_to_test_images):\n",
    "    # type_of_img = which group we want to compare: train or test\n",
    "    # atr = which type of dimension we want to compare.\n",
    "    if type_of_img=='train':\n",
    "        table = train_images_dims(train_path)\n",
    "    elif type_of_img=='test':\n",
    "        table = test_images_dims(test_path)\n",
    "    else:\n",
    "        raise ValueError(\"type_of_img has to be train or test\")\n",
    "    plt.hist(table[atr], density=True)\n",
    "    plt.xlim([0,180])\n",
    "    plt.title(f\"{type_of_img} data\")\n",
    "    plt.ylabel('density')\n",
    "    plt.xlabel(atr)\n",
    "    plt.show()\n",
    "    return(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6721f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compares height/width of test images to height/width of train images.\n",
    "def compre_train_test_img (atr='height', train_path=path_to_train_images, test_path=path_to_test_images):\n",
    "    # atr = which type of dimension we want to compare.\n",
    "    train_table= train_images_dims(train_path)\n",
    "    test_table = test_images_dims(test_path)\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.hist(train_table[atr], alpha=0.5, label=\"train\", density = True)\n",
    "    plt.hist(test_table[atr], alpha=0.5, label=\"test\", density = True)\n",
    "    plt.xlabel(atr, size=14)\n",
    "    plt.ylabel(\"density\", size=14)\n",
    "    plt.title(f\"compare train images {atr} to test images {atr}\")\n",
    "    plt.xlim([0,180])\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f12c634c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compares height of the images in test/train group to the width of images in test/train group\n",
    "def compare_dims_in_group(type_of_img, train_path=path_to_train_images, test_path=path_to_test_images):\n",
    "    # type_of_img = which group we want to compare: train or test\n",
    "    if type_of_img=='train':\n",
    "        table = train_images_dims(train_path)\n",
    "    elif type_of_img=='test':\n",
    "        table = test_images_dims(test_path)\n",
    "    else:\n",
    "        raise ValueError(\"type_of_img has to be train or test\")\n",
    "    plt.figure(figsize=(8,6))\n",
    "    plt.scatter(table.width, table.height)\n",
    "    plt.xlabel('width', size=14)\n",
    "    plt.ylabel(\"height\", size=14)\n",
    "    plt.title(f\"compare {type_of_img} width to {type_of_img} height\")\n",
    "    plt.xlim([0,180])\n",
    "    plt.ylim([0,180])\n",
    "    l = [i for i in range(0,180)]\n",
    "    plt.plot(l,l, color = 'black')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a50e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
