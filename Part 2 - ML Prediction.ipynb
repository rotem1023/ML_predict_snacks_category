{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70776db7",
   "metadata": {},
   "source": [
    "# <font color='purple'>ML Prediction - With Neural Networks </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "id": "e31f9b9b",
   "metadata": {
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import keras\n",
    "\n",
    "from functools import reduce\n",
    "from tensorflow import keras as ks\n",
    "from operator import itemgetter\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer as Tfidf\n",
    "from sklearn.pipeline import make_pipeline, make_union, Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, FunctionTransformer, Normalizer\n",
    "\n",
    "# Modeling & Model selection\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import KFold, train_test_split, cross_val_score\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "\n",
    "# Evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Configurations\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa336b9",
   "metadata": {},
   "source": [
    "## Help Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74407207",
   "metadata": {},
   "source": [
    "This function is meant for combining all data we have into a single Dataframe which contains a row for each product, thus making data like the nutrients available at the product level.\n",
    "\n",
    "We also merge it with our previous predictions from the CNN we created, and the predictions are added as another feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "id": "b4effaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_unified_df(test=False):\n",
    "    ntr = pd.read_csv(\"./data/nutrients.csv\")\n",
    "    food_ntr = pd.read_csv(\"./data/food_nutrients.csv\")\n",
    "    \n",
    "    ntr_combined = food_ntr.merge(ntr, on='nutrient_id', how='left')\n",
    "    all_ntr_lists = ntr_combined.groupby(\"idx\")[\"name\"].apply(list).apply(lambda x: \" \".join(x))\n",
    "    idx_nutrients = pd.DataFrame(all_ntr_lists).rename(columns={\"name\": \"nutrients_list\"})\n",
    "    \n",
    "    if test:\n",
    "        food = pd.read_csv(\"./data/food_test.csv\")\n",
    "    else:\n",
    "        food = pd.read_csv(\"./data/food_train.csv\")\n",
    "        \n",
    "    comb = food.merge(idx_nutrients, on=\"idx\")\n",
    "    \n",
    "    return comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "id": "cb8f9543",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data():\n",
    "    # Returns train data seperated in to features (X) df and target series (y)\n",
    "    df = prepare_unified_df(test=False)\n",
    "    # Shuffle the dataset\n",
    "#     df = df.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "    X = df.drop([\"category\"], axis=1)\n",
    "    y = df[\"category\"]\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "id": "7992be55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data():\n",
    "    # Returns features (X) of test data\n",
    "    return prepare_unified_df(test=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7416933e",
   "metadata": {},
   "source": [
    "This function is meant for:\n",
    "\n",
    "-  \"Cleaning\" existing columns like 'description', 'ingredients' and 'household_serving_fulltext' by filling Null values and more\n",
    "\n",
    "-  Combining the brand's name, the descrition and the household_serving_fulltext together to 1 column named 'text' - just becuase they are pretty similar in their meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "ef8bf7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df, with_cnn=False):\n",
    "    df[\"description\"] = df[\"description\"].str.strip('“').str.strip('”').str.strip('\"')\n",
    "    df[\"brand\"] = df[\"brand\"].fillna(\"\")\n",
    "    df[\"ingredients\"] = df[\"ingredients\"].fillna(\"\")  # Some Null values\n",
    "    df[\"household_serving_fulltext\"] = df[\"household_serving_fulltext\"].fillna(\"\")  # Some Null values\n",
    "    df[\"text\"] = reduce(lambda x, y: x + \" \" + y, (df[x].fillna(\"\") for x in [\n",
    "                                                                            \"brand\", \n",
    "                                                                            \"description\", \n",
    "                                                                            \"household_serving_fulltext\"\n",
    "                                                                            ]))\n",
    "    if with_cnn:\n",
    "        df = df[[\"brand\", \"text\", \"ingredients\", \"nutrients_list\", \"serving_size\", \"cnn_prediction\"]]\n",
    "        return df\n",
    "    \n",
    "    df = df[[\"brand\", \"text\", \"ingredients\", \"nutrients_list\", \"serving_size\"]]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6648cb9",
   "metadata": {},
   "source": [
    "**Prepare input data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "94621ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_num_of_ings_col(df):\n",
    "    df['n_ingredients'] = df['ingredients'].apply(lambda x: len(str(x).split(',')))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "id": "23d87b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_choc_in_row(v):\n",
    "    for i in v:\n",
    "        if type(i) == str:\n",
    "            if 'chocolate' in i.lower().strip():\n",
    "                return 'chocolate'\n",
    "    return 'no chocolate'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "id": "806afad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_field(f: str, *vec) -> Pipeline:\n",
    "    return make_pipeline(FunctionTransformer(itemgetter(f), validate=False), *vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "id": "6054db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vectorizer(with_cnn=False):\n",
    "    if with_cnn:\n",
    "        vectorizer = make_union(\n",
    "        on_field('brand', Tfidf(max_features=4000, token_pattern='\\w+', ngram_range=(1, 2))),\n",
    "        on_field('cnn_prediction', Tfidf(max_features=6, token_pattern='\\w+', ngram_range=(1, 1))),\n",
    "        on_field('text', Tfidf(max_features=10000, token_pattern='\\w+', ngram_range=(1, 2))),\n",
    "        on_field('ingredients', Tfidf(max_features=2000, token_pattern='\\w+', ngram_range=(1, 2))),\n",
    "        on_field('nutrients_list', Tfidf(max_features=2000, token_pattern='\\w+', ngram_range=(1, 2))),\n",
    "        on_field('is_chocolate_in_text', Tfidf(max_features=2, token_pattern='\\w+', ngram_range=(1, 1))),\n",
    "        on_field(['serving_size', 'n_ingredients'], FunctionTransformer(lambda x: x, validate=False)),\n",
    "        n_jobs=4\n",
    "        )\n",
    "        return vectorizer\n",
    "        \n",
    "    vectorizer = make_union(\n",
    "        on_field('brand', Tfidf(max_features=4000, token_pattern='\\w+', ngram_range=(1, 2))),\n",
    "        on_field('text', Tfidf(max_features=10000, token_pattern='\\w+', ngram_range=(1, 2))),\n",
    "        on_field('ingredients', Tfidf(max_features=2000, token_pattern='\\w+', ngram_range=(1, 2))),\n",
    "        on_field('nutrients_list', Tfidf(max_features=2000, token_pattern='\\w+', ngram_range=(1, 2))),\n",
    "        on_field('is_chocolate_in_text', Tfidf(max_features=2, token_pattern='\\w+', ngram_range=(1, 1))),\n",
    "        on_field(['serving_size', 'n_ingredients'], FunctionTransformer(lambda x: x, validate=False)),\n",
    "        n_jobs=4\n",
    "    )\n",
    "    return vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0aad9ba",
   "metadata": {},
   "source": [
    "This function is meant for preparing the X_train and X_test dataframes to be exactly as the NN model expects them to be. Here we:\n",
    "- Preprocess the data\n",
    "- Create the 'n_ingredients' 'is_chocolate_in_text' and features\n",
    "- scale the 'serving_size' and 'n_ingredients' features\n",
    "- Vectorize all text columns with TfidfVectorizer\n",
    "\n",
    "(Code is hidden as function is unfortunately long, appears in notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "id": "95385e4f",
   "metadata": {
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "def prepare_inputs(X_train, X_test, X_valid=None, has_valid=True, with_cnn=False):\n",
    "    \n",
    "    # Load actual test data\n",
    "    actual_test_data = load_test_data()\n",
    "    \n",
    "    preprocessed_X_train = preprocess(X_train, with_cnn=with_cnn)\n",
    "    preprocessed_X_test = preprocess(X_test, with_cnn=with_cnn)\n",
    "    preprocessed_actual_test_data = preprocess(actual_test_data, with_cnn=with_cnn)\n",
    "    \n",
    "    # Create new feature: Number of ingredints\n",
    "    preprocessed_X_train = add_num_of_ings_col(preprocessed_X_train)\n",
    "    preprocessed_X_test = add_num_of_ings_col(preprocessed_X_test)\n",
    "    preprocessed_actual_test_data = add_num_of_ings_col(preprocessed_actual_test_data)\n",
    "    \n",
    "    # Create new feature: Does the string \"chocolate\" appears somewhere in all text features\n",
    "    preprocessed_X_train[\"is_chocolate_in_text\"] = preprocessed_X_train.apply(is_choc_in_row, axis=1)\n",
    "    preprocessed_X_test[\"is_chocolate_in_text\"] = preprocessed_X_test.apply(is_choc_in_row, axis=1)\n",
    "    preprocessed_actual_test_data[\"is_chocolate_in_text\"] = preprocessed_actual_test_data.apply(is_choc_in_row, axis=1)\n",
    "    \n",
    "    # Scale numeric parameters\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(preprocessed_X_train.serving_size.values.reshape(-1, 1))\n",
    "    preprocessed_X_train[\"serving_size\"] = scaler.transform(preprocessed_X_train.serving_size.values.reshape(-1, 1))\n",
    "    preprocessed_X_test[\"serving_size\"] = scaler.transform(preprocessed_X_test.serving_size.values.reshape(-1, 1))\n",
    "    preprocessed_actual_test_data[\"serving_size\"] = scaler.transform(preprocessed_actual_test_data.serving_size.values.reshape(-1, 1))\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(preprocessed_X_train.n_ingredients.values.reshape(-1, 1))\n",
    "    preprocessed_X_train[\"n_ingredients\"] = scaler.transform(preprocessed_X_train.n_ingredients.values.reshape(-1, 1))\n",
    "    preprocessed_X_test[\"n_ingredients\"] = scaler.transform(preprocessed_X_test.n_ingredients.values.reshape(-1, 1))\n",
    "    preprocessed_actual_test_data[\"n_ingredients\"] = scaler.transform(preprocessed_actual_test_data.n_ingredients.values.reshape(-1, 1))\n",
    "    \n",
    "    if with_cnn:\n",
    "        vectorizer_cnn = create_vectorizer(with_cnn=True)\n",
    "        X_train_enc = vectorizer_cnn.fit_transform(preprocessed_X_train).astype(np.float32).toarray()\n",
    "        X_test_enc = vectorizer_cnn.transform(preprocessed_X_test).astype(np.float32).toarray()\n",
    "        actual_test_data_enc = vectorizer_cnn.transform(preprocessed_actual_test_data).astype(np.float32).toarray()\n",
    "    else:\n",
    "        vectorizer = create_vectorizer()\n",
    "        X_train_enc = vectorizer.fit_transform(preprocessed_X_train).astype(np.float32).toarray()\n",
    "        X_test_enc = vectorizer.transform(preprocessed_X_test).astype(np.float32).toarray()\n",
    "        actual_test_data_enc = vectorizer.transform(preprocessed_actual_test_data).astype(np.float32).toarray()\n",
    "    \n",
    "    if has_valid:\n",
    "        preprocessed_X_valid = preprocess(X_valid, with_cnn=with_cnn)\n",
    "        preprocessed_X_valid = add_num_of_ings_col(preprocessed_X_valid)\n",
    "        preprocessed_X_valid[\"is_chocolate_in_text\"] = preprocessed_X_valid.apply(is_choc_in_row, axis=1)\n",
    "        preprocessed_X_valid[\"serving_size\"] = scaler.transform(preprocessed_X_valid.serving_size.values.reshape(-1, 1))\n",
    "        preprocessed_X_valid[\"n_ingredients\"] = scaler.transform(preprocessed_X_valid.n_ingredients.values.reshape(-1, 1))\n",
    "        X_valid_enc = vectorizer.transform(preprocessed_X_valid).astype(np.float32).toarray()\n",
    "        \n",
    "        return X_train_enc, X_valid_enc, X_test_enc, actual_test_data_enc\n",
    "\n",
    "    return X_train_enc, X_test_enc, actual_test_data_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3af7c9e7",
   "metadata": {},
   "source": [
    "**Prepare target data**\n",
    "\n",
    "This function is meant for preparing the y_train and y_test arrays to be exactly as the NN model expects them to be. Here we encode the labels, and then use OH encoding to transform the data into the correct format for the NN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "id": "4b7781b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_targets(y_train, y_test, y_valid=None, has_valid=True):\n",
    "    le = LabelEncoder()\n",
    "    le.fit(y_train)\n",
    "    \n",
    "    le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "    print(le_name_mapping)\n",
    "    \n",
    "    y_train_enc = le.transform(y_train)\n",
    "    y_test_enc = le.transform(y_test)\n",
    "    \n",
    "    # One Hot encoding for output\n",
    "    y_train_enc = np_utils.to_categorical(y_train_enc)\n",
    "    y_test_enc = np_utils.to_categorical(y_test_enc)\n",
    "    \n",
    "    if has_valid:\n",
    "        y_valid_enc = le.transform(y_valid)\n",
    "        y_valid_enc = np_utils.to_categorical(y_valid_enc)\n",
    "        \n",
    "        return y_train_enc, y_valid_enc, y_test_enc\n",
    "    \n",
    "    return y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec980347",
   "metadata": {},
   "source": [
    "function for preparing all needed data for model:\n",
    "(Code is hidden, appears in notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "32c350b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {\n",
    "    0: \"cakes_cupcakes_snack_cakes\",\n",
    "    1: \"candy\", \n",
    "    2: \"chips_pretzels_snacks\",\n",
    "    3: \"chocolate\",\n",
    "    4: \"cookies_biscuits\",\n",
    "    5: \"popcorn_peanuts_seeds_related_snacks\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "id": "c150a268",
   "metadata": {
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "def get_data_for_model(test_size, with_valid=False, valid_size=0.1, random_state=1, with_cnn=False):\n",
    "    # Load data\n",
    "    X, y = load_train_data()\n",
    "    \n",
    "    if with_cnn:\n",
    "        cnn_df = pd.DataFrame()\n",
    "        for category_name in mapping.values():\n",
    "            tmp_df = pd.read_csv(f\"./cnn_predictions/{category_name}.csv\")\n",
    "            cnn_df = pd.concat([cnn_df, tmp_df])\n",
    "        cnn_df = cnn_df.astype(int)\n",
    "        cnn_df = cnn_df.sort_values('img', ignore_index=True)\n",
    "        cnn_df = cnn_df.rename(columns={\"prediction\": \"cnn_prediction\"})\n",
    "\n",
    "        X = X.merge(cnn_df, left_on=\"idx\", right_on=\"img\")\n",
    "\n",
    "        X[\"cnn_prediction\"] = X.cnn_prediction.apply(lambda x: mapping[x])\n",
    "\n",
    "    # Split to test set\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)\n",
    "    \n",
    "    if with_valid:\n",
    "        # Split rest to train and validation sets\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=valid_size, random_state=random_state)\n",
    "        # Prepare input data (X)\n",
    "        X_train, X_valid, X_test, _ = prepare_inputs(X_train, X_test, X_valid, with_cnn=with_cnn)\n",
    "        # prepare target data (Y)\n",
    "        y_train, y_valid, y_test = prepare_targets(y_train, y_test, y_valid)\n",
    "        \n",
    "        # Sanity check\n",
    "        print(\"Train:\")\n",
    "        print(f'\\tX_train: {X_train.shape} of {X_train.dtype}')\n",
    "        print(f'\\ty_train: {y_train.shape} of {y_train.dtype}')\n",
    "        print(\"Validation:\")\n",
    "        print(f'\\tX_valid: {X_valid.shape} of {X_valid.dtype}')\n",
    "        print(f'\\ty_valid: {y_valid.shape} of {y_valid.dtype}')\n",
    "        print(\"Test:\")\n",
    "        print(f'\\tX_test: {X_test.shape} of {X_test.dtype}')\n",
    "        print(f'\\ty_test: {y_test.shape} of {y_test.dtype}')\n",
    "        \n",
    "        return X_train, X_valid, X_test, y_train, y_valid, y_test\n",
    "    \n",
    "    else:\n",
    "        # Prepare input data (X)\n",
    "        X_train, X_test, _ = prepare_inputs(X_train, X_test, has_valid=False, with_cnn=with_cnn)\n",
    "        # prepare target data (Y)\n",
    "        y_train, y_test = prepare_targets(y_train, y_test, has_valid=False)\n",
    "        \n",
    "        print(\"Train:\")\n",
    "        print(f'\\tX_train: {X_train.shape} of {X_train.dtype}')\n",
    "        print(f'\\ty_train: {y_train.shape} of {y_train.dtype}')\n",
    "        print(\"Test:\")\n",
    "        print(f'\\tX_test: {X_test.shape} of {X_test.dtype}')\n",
    "        print(f'\\ty_test: {y_test.shape} of {y_test.dtype}')\n",
    "        \n",
    "        return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9ba657",
   "metadata": {},
   "source": [
    "Function for plotting the train and validation accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "id": "58cdfae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_accuracy(history):\n",
    "    history_dict = history.history\n",
    "\n",
    "    acc = history_dict['accuracy']\n",
    "    val_acc = history_dict['val_accuracy']\n",
    "\n",
    "    # range of X (no. of epochs)\n",
    "    epochs = range(1, len(acc) + 1)\n",
    "\n",
    "    # plot\n",
    "    plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "    plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "    plt.title('Training and validation accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b8abed5",
   "metadata": {},
   "source": [
    "**First model creation:**\n",
    "\n",
    "This model configuration was chosen after we tried several different parameters manually, such as number of layers (3 always seemed to work better than 2), number of nuerons per layer and the dropout rate. But we'll do some CV later!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "id": "ae39922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(dp=0.4, optimizer='adam', num_nuerons=[128, 32, 16]):\n",
    "    model_in = ks.Input(shape=(INPUT_SHAPE,), dtype='float32', sparse=True)\n",
    "    out = ks.layers.Dense(num_nuerons[0], activation='relu')(model_in)\n",
    "    out = ks.layers.Dropout(dp)(out)\n",
    "    out = ks.layers.Dense(num_nuerons[1], activation='relu')(out)\n",
    "    out = ks.layers.Dropout(dp)(out)\n",
    "    out = ks.layers.Dense(num_nuerons[2], activation='relu')(out)\n",
    "    out = ks.layers.Dense(6, activation='softmax')(out)\n",
    "    model = ks.Model(model_in, out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) # rmsprop/adam\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "id": "0d79e5ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback\n",
    "es = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=10,  # stop training when there's no improvement in val_loss for 10 consecutive epochs\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30a78564",
   "metadata": {},
   "source": [
    "## 1st Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eba5fbf",
   "metadata": {},
   "source": [
    "### Get Data & Run NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "8a17112e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cakes_cupcakes_snack_cakes': 0, 'candy': 1, 'chips_pretzels_snacks': 2, 'chocolate': 3, 'cookies_biscuits': 4, 'popcorn_peanuts_seeds_related_snacks': 5}\n",
      "Train:\n",
      "\tX_train: (24289, 16439) of float32\n",
      "\ty_train: (24289, 6) of float32\n",
      "Validation:\n",
      "\tX_valid: (2699, 16439) of float32\n",
      "\ty_valid: (2699, 6) of float32\n",
      "Test:\n",
      "\tX_test: (4763, 16439) of float32\n",
      "\ty_test: (4763, 6) of float32\n"
     ]
    }
   ],
   "source": [
    "# Get data\n",
    "X_train, X_valid, X_test, y_train, y_valid, y_test = get_data_for_model(\n",
    "    test_size=0.15,\n",
    "    with_valid=True,\n",
    "    valid_size=0.1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "2c82f32e",
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "760/760 - 4s - loss: 0.5122 - accuracy: 0.8295 - val_loss: 0.2382 - val_accuracy: 0.9322 - 4s/epoch - 6ms/step\n",
      "Epoch 2/10000\n",
      "760/760 - 3s - loss: 0.2196 - accuracy: 0.9332 - val_loss: 0.2416 - val_accuracy: 0.9337 - 3s/epoch - 4ms/step\n",
      "Epoch 3/10000\n",
      "760/760 - 3s - loss: 0.1623 - accuracy: 0.9487 - val_loss: 0.2613 - val_accuracy: 0.9252 - 3s/epoch - 4ms/step\n",
      "Epoch 4/10000\n",
      "760/760 - 3s - loss: 0.1314 - accuracy: 0.9571 - val_loss: 0.2900 - val_accuracy: 0.9307 - 3s/epoch - 4ms/step\n",
      "Epoch 5/10000\n",
      "760/760 - 3s - loss: 0.1101 - accuracy: 0.9650 - val_loss: 0.2897 - val_accuracy: 0.9337 - 3s/epoch - 4ms/step\n",
      "Epoch 6/10000\n",
      "760/760 - 3s - loss: 0.0925 - accuracy: 0.9691 - val_loss: 0.3236 - val_accuracy: 0.9329 - 3s/epoch - 4ms/step\n",
      "Epoch 7/10000\n",
      "760/760 - 3s - loss: 0.0810 - accuracy: 0.9725 - val_loss: 0.3445 - val_accuracy: 0.9303 - 3s/epoch - 4ms/step\n",
      "Epoch 8/10000\n",
      "760/760 - 3s - loss: 0.0704 - accuracy: 0.9742 - val_loss: 0.3530 - val_accuracy: 0.9322 - 3s/epoch - 4ms/step\n",
      "Epoch 9/10000\n",
      "760/760 - 3s - loss: 0.0623 - accuracy: 0.9774 - val_loss: 0.3595 - val_accuracy: 0.9311 - 3s/epoch - 4ms/step\n",
      "Epoch 10/10000\n",
      "760/760 - 3s - loss: 0.0564 - accuracy: 0.9816 - val_loss: 0.4000 - val_accuracy: 0.9315 - 3s/epoch - 4ms/step\n",
      "Epoch 11/10000\n",
      "760/760 - 4s - loss: 0.0520 - accuracy: 0.9821 - val_loss: 0.4135 - val_accuracy: 0.9329 - 4s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "INPUT_SHAPE = X_train.shape[1]\n",
    "model = create_model()\n",
    "\n",
    "# Fit model on training data\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    callbacks=[es],\n",
    "    epochs=10000,\n",
    "    shuffle=True,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5854d2c6",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49078b68",
   "metadata": {},
   "source": [
    "**Plotting training and validation accuracy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "id": "cf900f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12dd5934",
   "metadata": {},
   "source": [
    "**Classification Report on validation data:**\n",
    "\n",
    "(validation data was used by the model for estimating performance, but model was not trained on it!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "d15bf8ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       335\n",
      "           1       0.94      0.90      0.92       620\n",
      "           2       0.98      0.96      0.97       335\n",
      "           3       0.80      0.89      0.84       319\n",
      "           4       0.96      0.93      0.94       454\n",
      "           5       0.96      0.94      0.95       636\n",
      "\n",
      "    accuracy                           0.93      2699\n",
      "   macro avg       0.93      0.93      0.93      2699\n",
      "weighted avg       0.93      0.93      0.93      2699\n",
      "\n",
      "Accuracy on validation: 93.22\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_valid, verbose=0)\n",
    "# Classification report\n",
    "print(classification_report(y_valid.argmax(axis=1), preds.argmax(axis=1)))\n",
    "_, accuracy = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "print('Accuracy on validation: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514b7f26",
   "metadata": {},
   "source": [
    "**Classification Report on test data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "c759b872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96       565\n",
      "           1       0.96      0.91      0.93      1120\n",
      "           2       0.97      0.96      0.97       536\n",
      "           3       0.82      0.91      0.86       591\n",
      "           4       0.93      0.95      0.94       818\n",
      "           5       0.97      0.96      0.96      1133\n",
      "\n",
      "    accuracy                           0.94      4763\n",
      "   macro avg       0.93      0.94      0.94      4763\n",
      "weighted avg       0.94      0.94      0.94      4763\n",
      "\n",
      "Accuracy on test: 93.83\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "# Classification report\n",
    "print(classification_report(y_test.argmax(axis=1), preds.argmax(axis=1)))\n",
    "\n",
    "_, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy on test: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0649575",
   "metadata": {},
   "source": [
    "### Before we continue, let's train this model on all data and save a prediction in the test set, in case this will be one of our final models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "db172c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cakes_cupcakes_snack_cakes': 0, 'candy': 1, 'chips_pretzels_snacks': 2, 'chocolate': 3, 'cookies_biscuits': 4, 'popcorn_peanuts_seeds_related_snacks': 5}\n",
      "Train:\n",
      "\ttrain_data: (31751, 16446) of float32\n",
      "\ty: (31751, 6) of float32\n",
      "Test:\n",
      "\ttest_data: (3525, 16446) of float32\n"
     ]
    }
   ],
   "source": [
    "train_data, y = load_train_data()\n",
    "train_data, _, test_data = prepare_inputs(train_data, train_data, has_valid=False)\n",
    "\n",
    "y, _ = prepare_targets(y, y, has_valid=False)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(f'\\ttrain_data: {train_data.shape} of {train_data.dtype}')\n",
    "print(f'\\ty: {y.shape} of {y.dtype}')\n",
    "print(\"Test:\")\n",
    "print(f'\\ttest_data: {test_data.shape} of {test_data.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "87cef037",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model\n",
    "INPUT_SHAPE = train_data.shape[1]\n",
    "model = create_model()\n",
    "\n",
    "# Fit model on all train data\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    y,\n",
    "    epochs=10,  # We see that there's almost no improvement after a couple of epochs, so we need it to avoid overfitting.\n",
    "    shuffle=True,\n",
    "    verbose=0\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679b9617",
   "metadata": {},
   "source": [
    "#### Sanity check on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "eada4d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00      3786\n",
      "           1       0.99      0.97      0.98      7584\n",
      "           2       1.00      1.00      1.00      3680\n",
      "           3       0.94      0.98      0.96      3772\n",
      "           4       1.00      0.99      0.99      5284\n",
      "           5       1.00      0.99      1.00      7645\n",
      "\n",
      "    accuracy                           0.99     31751\n",
      "   macro avg       0.99      0.99      0.99     31751\n",
      "weighted avg       0.99      0.99      0.99     31751\n",
      "\n",
      "Accuracy on validation: 98.88\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(train_data, verbose=0)\n",
    "# Classification report\n",
    "print(classification_report(y.argmax(axis=1), preds.argmax(axis=1)))\n",
    "_, accuracy = model.evaluate(train_data, y, verbose=0)\n",
    "print('Accuracy on validation: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b1aea5",
   "metadata": {},
   "source": [
    "#### Predict on test data and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "03241404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(test_data).argmax(axis=1)\n",
    "\n",
    "mapping = {\n",
    "    0: \"cakes_cupcakes_snack_cakes\",\n",
    "    1: \"candy\", \n",
    "    2: \"chips_pretzels_snacks\",\n",
    "    3: \"chocolate\",\n",
    "    4: \"cookies_biscuits\",\n",
    "    5: \"popcorn_peanuts_seeds_related_snacks\"\n",
    "}\n",
    "\n",
    "preds = [mapping[i] for i in preds]\n",
    "\n",
    "test_indexes = load_test_data().idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "90c3a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_model_03 = pd.DataFrame({\"idx\": indexes, \"pred_cat\": preds})\n",
    "results_model_03.to_csv(\"model_03.csv\", index=False)\n",
    "\n",
    "# For sanity check\n",
    "t = load_test_data()\n",
    "t[\"pred_cat\"] = preds\n",
    "t.to_csv(\"model_03_check.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8c3e3e",
   "metadata": {},
   "source": [
    "**Notice:** Here you see creation of model 3, which includes the \"is_chocolate\" feature. Model 1 which we created is the same model, but without this feature, and was run before this feature was added to our code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a257c059",
   "metadata": {},
   "source": [
    "### Conclusions until now:\n",
    "\n",
    "1) We see that the precision and recall of all 6 categories are pretty similar, so we can assure ourselves that using accuracy is indeed OK.\n",
    "\n",
    "2) We see that we get a pretty good accuracy without needing to do any complicated manipulations on the tabular data, and overall it really makes sense, as we saw in the data exploration step that the data is mostly text, and that these texts, such as brand, description and ingredients, hold most of the information we need to know the category. So, by using Tfidf to convert the text to TF-IDF features, we really use all this information.\n",
    "\n",
    "3) We also see that the validation accuracy doesn't really go up, so we need to be cautious of overfitting. It seems that increasing the epochs is definitely not the solution (we're just staying with the same validation accuracy), so improving the model with have to come from improving the hyperparameters or adding additional data.\n",
    "\n",
    "4) We can see that the f1 score of category #3 (it's choclate) is very low compared to all other categories. That means that we do a not-so-good job at predicting the Choclate category, and we need to go back to the data and see if there's some information that we can use to improve this.\n",
    "\n",
    "So, this is going to be our next step!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0e6f65",
   "metadata": {},
   "source": [
    "## 2nd Model:  Adding additional params to improve *Choclate* classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12174c22",
   "metadata": {},
   "source": [
    "#### Updating relevant functions:\n",
    "For now we create new versions of create_vectorizer and prepare_inputs, as we're not sure yet we want this feature in our final model (Code is hidden, appears in notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "id": "d73e0e11",
   "metadata": {
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "def is_choc_in_row(v):\n",
    "    for i in v:\n",
    "        if type(i) == str:\n",
    "            if 'chocolate' in i.lower().strip():\n",
    "                return 'chocolate'\n",
    "    return 'no chocolate'\n",
    "\n",
    "def create_vectorizer_2():\n",
    "    vectorizer = make_union(\n",
    "        on_field('brand', Tfidf(max_features=4000, token_pattern='\\w+', ngram_range=(1, 2))),\n",
    "        on_field('text', Tfidf(max_features=10000, token_pattern='\\w+', ngram_range=(1, 2))),\n",
    "        on_field('ingredients', Tfidf(max_features=2000, token_pattern='\\w+', ngram_range=(1, 2))),\n",
    "        on_field('nutrients_list', Tfidf(max_features=2000, token_pattern='\\w+', ngram_range=(1, 2))),\n",
    "        on_field('is_chocolate_in_text', Tfidf(max_features=2, token_pattern='\\w+', ngram_range=(1, 1))),\n",
    "        on_field(['serving_size', 'n_ingredients'], \n",
    "                 FunctionTransformer(lambda x: x, validate=False))\n",
    "    )\n",
    "    return vectorizer\n",
    "\n",
    "\n",
    "def prepare_inputs_2(X_train, X_test, X_valid=None, has_valid=True):\n",
    "    preprocessed_X_train = preprocess(X_train)\n",
    "    preprocessed_X_test = preprocess(X_test)\n",
    "    \n",
    "    # Create new feature: Number of ingredints\n",
    "    preprocessed_X_train = add_num_of_ings_col(preprocessed_X_train)\n",
    "    preprocessed_X_test = add_num_of_ings_col(preprocessed_X_test)\n",
    "    \n",
    "    # Create new feature:\n",
    "    preprocessed_X_train[\"is_chocolate_in_text\"] = preprocessed_X_train.apply(is_choc_in_row, axis=1)\n",
    "    preprocessed_X_test[\"is_chocolate_in_text\"] = preprocessed_X_test.apply(is_choc_in_row, axis=1)\n",
    "    \n",
    "    # Scale numeric parameters\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(preprocessed_X_train.serving_size.values.reshape(-1, 1))\n",
    "    preprocessed_X_train[\"serving_size\"] = scaler.transform(preprocessed_X_train.serving_size.values.reshape(-1, 1))\n",
    "    preprocessed_X_test[\"serving_size\"] = scaler.transform(preprocessed_X_test.serving_size.values.reshape(-1, 1))\n",
    "    \n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(preprocessed_X_train.n_ingredients.values.reshape(-1, 1))\n",
    "    preprocessed_X_train[\"n_ingredients\"] = scaler.transform(preprocessed_X_train.n_ingredients.values.reshape(-1, 1))\n",
    "    preprocessed_X_test[\"n_ingredients\"] = scaler.transform(preprocessed_X_test.n_ingredients.values.reshape(-1, 1))\n",
    "    \n",
    "    # Vectorize\n",
    "    vectorizer = create_vectorizer_2()\n",
    "    X_train_enc = vectorizer.fit_transform(preprocessed_X_train).astype(np.float32).toarray()\n",
    "    X_test_enc = vectorizer.transform(preprocessed_X_test).astype(np.float32).toarray()\n",
    "    \n",
    "    if has_valid:\n",
    "        preprocessed_X_valid = preprocess(X_valid)\n",
    "        preprocessed_X_valid = add_num_of_ings_col(preprocessed_X_valid)\n",
    "        preprocessed_X_valid[\"is_chocolate_in_text\"] = preprocessed_X_valid.apply(is_choc_in_row, axis=1)\n",
    "        preprocessed_X_valid[\"serving_size\"] = scaler.transform(preprocessed_X_valid.serving_size.values.reshape(-1, 1))\n",
    "        preprocessed_X_valid[\"n_ingredients\"] = scaler.transform(preprocessed_X_valid.n_ingredients.values.reshape(-1, 1))\n",
    "        X_valid_enc = vectorizer.transform(preprocessed_X_valid).astype(np.float32).toarray()\n",
    "        \n",
    "        return X_train_enc, X_valid_enc, X_test_enc\n",
    "    \n",
    " \n",
    "    return X_train_enc, X_test_enc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e84f34",
   "metadata": {},
   "source": [
    "### Prepare data & Run NN model with new feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "id": "9a17d1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cakes_cupcakes_snack_cakes': 0, 'candy': 1, 'chips_pretzels_snacks': 2, 'chocolate': 3, 'cookies_biscuits': 4, 'popcorn_peanuts_seeds_related_snacks': 5}\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X, y = load_train_data()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.1, random_state=1)\n",
    "# Use prepare_inputs_2 functions and not original one\n",
    "X_train, X_valid, X_test = prepare_inputs_2(X_train, X_test, X_valid)\n",
    "y_train, y_valid, y_test = prepare_targets(y_train, y_test, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "id": "d215f064",
   "metadata": {
    "scrolled": true,
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "1519/1519 - 6s - loss: 0.4669 - accuracy: 0.8483 - val_loss: 0.2398 - val_accuracy: 0.9244 - 6s/epoch - 4ms/step\n",
      "Epoch 2/10000\n",
      "1519/1519 - 5s - loss: 0.2046 - accuracy: 0.9352 - val_loss: 0.2352 - val_accuracy: 0.9326 - 5s/epoch - 4ms/step\n",
      "Epoch 3/10000\n",
      "1519/1519 - 6s - loss: 0.1604 - accuracy: 0.9486 - val_loss: 0.2384 - val_accuracy: 0.9333 - 6s/epoch - 4ms/step\n",
      "Epoch 4/10000\n",
      "1519/1519 - 5s - loss: 0.1278 - accuracy: 0.9584 - val_loss: 0.2559 - val_accuracy: 0.9363 - 5s/epoch - 4ms/step\n",
      "Epoch 5/10000\n",
      "1519/1519 - 6s - loss: 0.1071 - accuracy: 0.9650 - val_loss: 0.2920 - val_accuracy: 0.9366 - 6s/epoch - 4ms/step\n",
      "Epoch 6/10000\n",
      "1519/1519 - 6s - loss: 0.0883 - accuracy: 0.9694 - val_loss: 0.3293 - val_accuracy: 0.9307 - 6s/epoch - 4ms/step\n",
      "Epoch 7/10000\n",
      "1519/1519 - 6s - loss: 0.0828 - accuracy: 0.9720 - val_loss: 0.3077 - val_accuracy: 0.9381 - 6s/epoch - 4ms/step\n",
      "Epoch 8/10000\n",
      "1519/1519 - 6s - loss: 0.0747 - accuracy: 0.9752 - val_loss: 0.3536 - val_accuracy: 0.9296 - 6s/epoch - 4ms/step\n",
      "Epoch 9/10000\n",
      "1519/1519 - 7s - loss: 0.0668 - accuracy: 0.9775 - val_loss: 0.3774 - val_accuracy: 0.9289 - 7s/epoch - 5ms/step\n",
      "Epoch 10/10000\n",
      "1519/1519 - 6s - loss: 0.0630 - accuracy: 0.9795 - val_loss: 0.3863 - val_accuracy: 0.9315 - 6s/epoch - 4ms/step\n",
      "Epoch 11/10000\n",
      "1519/1519 - 6s - loss: 0.0536 - accuracy: 0.9822 - val_loss: 0.3933 - val_accuracy: 0.9318 - 6s/epoch - 4ms/step\n",
      "Epoch 12/10000\n",
      "1519/1519 - 6s - loss: 0.0501 - accuracy: 0.9823 - val_loss: 0.4515 - val_accuracy: 0.9296 - 6s/epoch - 4ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "INPUT_SHAPE = X_train.shape[1]\n",
    "model = create_model()\n",
    "\n",
    "# Fit model on training data\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    callbacks=[es],\n",
    "    epochs=10000,\n",
    "    batch_size=16,\n",
    "    shuffle=True,\n",
    "    validation_data=(X_valid, y_valid),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663d5778",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388dbc6e",
   "metadata": {},
   "source": [
    "**Plotting training and validation accuracy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "id": "62a57280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19bb9eaf",
   "metadata": {},
   "source": [
    "**Classification Report on validation data:**\n",
    "\n",
    "(validation data was used by the model for estimating performance, but model was not trained on it!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "id": "81c19b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97       335\n",
      "           1       0.91      0.93      0.92       620\n",
      "           2       0.99      0.95      0.97       335\n",
      "           3       0.83      0.84      0.83       319\n",
      "           4       0.96      0.92      0.94       454\n",
      "           5       0.95      0.96      0.96       636\n",
      "\n",
      "    accuracy                           0.93      2699\n",
      "   macro avg       0.93      0.93      0.93      2699\n",
      "weighted avg       0.93      0.93      0.93      2699\n",
      "\n",
      "Accuracy on validation: 93.26\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_valid, verbose=0)\n",
    "# Classification report\n",
    "print(classification_report(y_valid.argmax(axis=1), preds.argmax(axis=1)))\n",
    "\n",
    "_, accuracy = model.evaluate(X_valid, y_valid, verbose=0)\n",
    "print('Accuracy on validation: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e40bd10b",
   "metadata": {},
   "source": [
    "**Classification Report on test data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "id": "9f1e0886",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.97      0.97       565\n",
      "           1       0.92      0.94      0.93      1120\n",
      "           2       0.96      0.97      0.97       536\n",
      "           3       0.84      0.85      0.84       591\n",
      "           4       0.94      0.95      0.95       818\n",
      "           5       0.97      0.95      0.96      1133\n",
      "\n",
      "    accuracy                           0.94      4763\n",
      "   macro avg       0.94      0.94      0.94      4763\n",
      "weighted avg       0.94      0.94      0.94      4763\n",
      "\n",
      "Accuracy on test: 93.81\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test, verbose=0)\n",
    "# Classification report\n",
    "print(classification_report(y_test.argmax(axis=1), preds.argmax(axis=1)))\n",
    "\n",
    "_, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Accuracy on test: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c0f036",
   "metadata": {},
   "source": [
    "Seems like it help! f1-score of category #3 goes from 82-83 to 85.\n",
    "So we'll add it to our model :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2278f7f0",
   "metadata": {},
   "source": [
    "**Notice**: When you go thourgh this notebook, you'll notice that this feature is already included in the initial functions, but that was done **after** this section was completed and we saw that this feature actually help us"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0783ead",
   "metadata": {},
   "source": [
    "## Cross Validation for hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "de5bab8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cakes_cupcakes_snack_cakes': 0, 'candy': 1, 'chips_pretzels_snacks': 2, 'chocolate': 3, 'cookies_biscuits': 4, 'popcorn_peanuts_seeds_related_snacks': 5}\n",
      "Train:\n",
      "\tX_train: (25400, 16436) of float32\n",
      "\ty_train: (25400, 6) of float32\n",
      "Test:\n",
      "\tX_test: (6351, 16436) of float32\n",
      "\ty_test: (6351, 6) of float32\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test = get_data_for_model(test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "871fcadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback for CV\n",
    "es_cv = keras.callbacks.EarlyStopping(\n",
    "    monitor='loss',\n",
    "    mode='min',\n",
    "    patience=10,  # stop training when there's no improvement in loss for 10 consecutive epochs\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "e88835f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_cv(dp=0.4, optimizer='adam', init='glorot_uniform', n_neurons=128):\n",
    "    model_in = ks.Input(shape=(INPUT_SHAPE,), dtype='float32', sparse=True)\n",
    "    out = ks.layers.Dense(n_neurons, activation='relu', kernel_initializer=init)(model_in)\n",
    "    out = ks.layers.Dropout(dp)(out)\n",
    "    out = ks.layers.Dense(n_neurons//2, activation='relu', kernel_initializer=init)(out)\n",
    "    out = ks.layers.Dropout(dp)(out)\n",
    "    out = ks.layers.Dense(n_neurons//8, activation='relu', kernel_initializer=init)(out)\n",
    "    out = ks.layers.Dense(6, activation='softmax')(out)\n",
    "    model = ks.Model(model_in, out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) # rmsprop/adam\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "052b9462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create KerasClassifier\n",
    "INPUT_SHAPE = X_train.shape[1]\n",
    "model_CV = KerasClassifier(\n",
    "    model=create_model_cv, \n",
    "    callbacks=[es_cv], \n",
    "    loss=\"categorical_crossentropy\",\n",
    "    dp=None, \n",
    "    optimizer=None, \n",
    "    init=None, \n",
    "    n_neurons=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb584cd7",
   "metadata": {},
   "source": [
    "#### Define parameters for grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "25c74386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': [16],\n",
       " 'dp': [0.2, 0.4, 0.6],\n",
       " 'optimizer': ['adam'],\n",
       " 'epochs': [3, 6, 10],\n",
       " 'n_neurons': [128, 192, 256]}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dp = [0.2, 0.4, 0.6]\n",
    "optimizer = [\"adam\"]\n",
    "batches = [16]\n",
    "n_neurons = [128, 192, 256]\n",
    "epochs = [3, 6, 10]\n",
    "\n",
    "param_grid = dict(\n",
    "    batch_size=batches,\n",
    "    dp=dp, \n",
    "    optimizer=optimizer,\n",
    "    epochs=epochs,\n",
    "    n_neurons=n_neurons\n",
    ")\n",
    "\n",
    "param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "4ed9507c",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model_CV, param_grid=param_grid, cv=3, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "aa348353",
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.3780 - accuracy: 0.8736\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1505 - accuracy: 0.9492\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0943 - accuracy: 0.9667\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=3, n_neurons=128, optimizer=adam; total time=  15.9s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.3852 - accuracy: 0.8807\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1431 - accuracy: 0.9506\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0957 - accuracy: 0.9657\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=3, n_neurons=128, optimizer=adam; total time=  15.5s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.3820 - accuracy: 0.8766\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1479 - accuracy: 0.9486\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0974 - accuracy: 0.9645\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=3, n_neurons=128, optimizer=adam; total time=  18.4s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.3557 - accuracy: 0.8806\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1396 - accuracy: 0.9511\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0894 - accuracy: 0.9682\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=3, n_neurons=192, optimizer=adam; total time=  46.2s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.3536 - accuracy: 0.8846\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1388 - accuracy: 0.9536\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0920 - accuracy: 0.9676\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=3, n_neurons=192, optimizer=adam; total time=  19.3s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.3653 - accuracy: 0.8797\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1418 - accuracy: 0.9518\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0922 - accuracy: 0.9665\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=3, n_neurons=192, optimizer=adam; total time=  20.3s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.3344 - accuracy: 0.8864\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.1400 - accuracy: 0.9522\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0898 - accuracy: 0.9666\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=3, n_neurons=256, optimizer=adam; total time=  28.5s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.3380 - accuracy: 0.8892\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.1409 - accuracy: 0.9531\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0871 - accuracy: 0.9693\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=3, n_neurons=256, optimizer=adam; total time=  29.1s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.3372 - accuracy: 0.8871\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.1404 - accuracy: 0.9507\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0922 - accuracy: 0.9646\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=3, n_neurons=256, optimizer=adam; total time=  28.1s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.3800 - accuracy: 0.8785\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1486 - accuracy: 0.9513\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0985 - accuracy: 0.9649\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0700 - accuracy: 0.9751\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0520 - accuracy: 0.9822\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0423 - accuracy: 0.9839\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=6, n_neurons=128, optimizer=adam; total time=  28.0s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 6s 4ms/step - loss: 0.3721 - accuracy: 0.8797\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1456 - accuracy: 0.9515\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0961 - accuracy: 0.9663\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0651 - accuracy: 0.9768\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0495 - accuracy: 0.9832\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0396 - accuracy: 0.9848\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=6, n_neurons=128, optimizer=adam; total time=  45.7s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.3867 - accuracy: 0.8717\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1538 - accuracy: 0.9487\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1015 - accuracy: 0.9640\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0709 - accuracy: 0.9734\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0590 - accuracy: 0.9787\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0434 - accuracy: 0.9843\n",
      "530/530 [==============================] - 1s 1ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=6, n_neurons=128, optimizer=adam; total time=  28.3s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.3395 - accuracy: 0.8855\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1440 - accuracy: 0.9494\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0889 - accuracy: 0.9673\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0639 - accuracy: 0.9745\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0477 - accuracy: 0.9813\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0393 - accuracy: 0.9856\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=6, n_neurons=192, optimizer=adam; total time=  34.8s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.3522 - accuracy: 0.8802\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1385 - accuracy: 0.9518\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0893 - accuracy: 0.9692\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0644 - accuracy: 0.9769\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0477 - accuracy: 0.9813\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0365 - accuracy: 0.9862\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=6, n_neurons=192, optimizer=adam; total time=  34.7s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.3488 - accuracy: 0.8845\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1389 - accuracy: 0.9519\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0919 - accuracy: 0.9660\n",
      "Epoch 4/6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0659 - accuracy: 0.9752\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0509 - accuracy: 0.9815\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0407 - accuracy: 0.9849\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=6, n_neurons=192, optimizer=adam; total time=  34.9s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.3353 - accuracy: 0.8867\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1413 - accuracy: 0.9515\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0909 - accuracy: 0.9682\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0667 - accuracy: 0.9747\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0504 - accuracy: 0.9811\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.0424 - accuracy: 0.9827\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=6, n_neurons=256, optimizer=adam; total time=  51.2s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.3444 - accuracy: 0.8858\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.1387 - accuracy: 0.9534\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0871 - accuracy: 0.9698\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0651 - accuracy: 0.9765\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0480 - accuracy: 0.9807\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0387 - accuracy: 0.9862\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=6, n_neurons=256, optimizer=adam; total time=  51.4s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 10s 8ms/step - loss: 0.3441 - accuracy: 0.8853\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1366 - accuracy: 0.9531\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0920 - accuracy: 0.9654\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0658 - accuracy: 0.9761\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0521 - accuracy: 0.9797\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0417 - accuracy: 0.9848\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=6, n_neurons=256, optimizer=adam; total time=  51.6s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.3806 - accuracy: 0.8740\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1485 - accuracy: 0.9507\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0954 - accuracy: 0.9668\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.0687 - accuracy: 0.9750\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0511 - accuracy: 0.9805\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0401 - accuracy: 0.9847\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.0337 - accuracy: 0.9871\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0295 - accuracy: 0.9906\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0250 - accuracy: 0.9911\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0225 - accuracy: 0.9916\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=10, n_neurons=128, optimizer=adam; total time=  41.4s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.3893 - accuracy: 0.8708\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1502 - accuracy: 0.9503\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0956 - accuracy: 0.9656\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0645 - accuracy: 0.9763\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0522 - accuracy: 0.9810\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0417 - accuracy: 0.9852\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0318 - accuracy: 0.9876\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0268 - accuracy: 0.9901\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0233 - accuracy: 0.9907\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0216 - accuracy: 0.9918\n",
      "530/530 [==============================] - 1s 1ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=10, n_neurons=128, optimizer=adam; total time=  42.5s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.3866 - accuracy: 0.8753\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1508 - accuracy: 0.9496\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0984 - accuracy: 0.9649\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0719 - accuracy: 0.9725\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0538 - accuracy: 0.9798\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0437 - accuracy: 0.9842\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0351 - accuracy: 0.9872\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0282 - accuracy: 0.9898\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0267 - accuracy: 0.9906\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0237 - accuracy: 0.9916\n",
      "530/530 [==============================] - 1s 1ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=10, n_neurons=128, optimizer=adam; total time=  50.8s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.3607 - accuracy: 0.8822\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1433 - accuracy: 0.9504\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0908 - accuracy: 0.9670\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0667 - accuracy: 0.9751\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0509 - accuracy: 0.9805\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0372 - accuracy: 0.9842\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0328 - accuracy: 0.9874\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0266 - accuracy: 0.9897\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0222 - accuracy: 0.9912\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0212 - accuracy: 0.9921\n",
      "530/530 [==============================] - 2s 3ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=10, n_neurons=192, optimizer=adam; total time=  59.2s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.3517 - accuracy: 0.8833\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1406 - accuracy: 0.9525\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0871 - accuracy: 0.9682\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0653 - accuracy: 0.9767\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0505 - accuracy: 0.9805\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0367 - accuracy: 0.9860\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0301 - accuracy: 0.9886\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0262 - accuracy: 0.9911\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0234 - accuracy: 0.9913\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0213 - accuracy: 0.9922\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=10, n_neurons=192, optimizer=adam; total time=  57.9s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.3530 - accuracy: 0.8840\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1415 - accuracy: 0.9514\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0936 - accuracy: 0.9658\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0702 - accuracy: 0.9756\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0524 - accuracy: 0.9800\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0416 - accuracy: 0.9843\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0336 - accuracy: 0.9878\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0296 - accuracy: 0.9887\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0242 - accuracy: 0.9916\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0206 - accuracy: 0.9920\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=10, n_neurons=192, optimizer=adam; total time=  53.4s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.3372 - accuracy: 0.8868\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1380 - accuracy: 0.9528\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0900 - accuracy: 0.9668\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0632 - accuracy: 0.9761\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0478 - accuracy: 0.9810\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0414 - accuracy: 0.9846\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0329 - accuracy: 0.9866\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0295 - accuracy: 0.9890\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0240 - accuracy: 0.9912\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0187 - accuracy: 0.9929\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=10, n_neurons=256, optimizer=adam; total time= 1.4min\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.3325 - accuracy: 0.8893\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1369 - accuracy: 0.9538\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0898 - accuracy: 0.9689\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.0612 - accuracy: 0.9777\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0463 - accuracy: 0.9825\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0401 - accuracy: 0.9856\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0294 - accuracy: 0.9891\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0287 - accuracy: 0.9891\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0207 - accuracy: 0.9921\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0229 - accuracy: 0.9926\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=10, n_neurons=256, optimizer=adam; total time= 1.4min\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.3416 - accuracy: 0.8863\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1430 - accuracy: 0.9500\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0900 - accuracy: 0.9659\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0693 - accuracy: 0.9744\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0502 - accuracy: 0.9807\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0403 - accuracy: 0.9857\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0359 - accuracy: 0.9869\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0264 - accuracy: 0.9900\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0246 - accuracy: 0.9907\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0210 - accuracy: 0.9917\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.2, epochs=10, n_neurons=256, optimizer=adam; total time= 1.4min\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.4579 - accuracy: 0.8450\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1863 - accuracy: 0.9408\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1348 - accuracy: 0.9554\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=3, n_neurons=128, optimizer=adam; total time=  15.2s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.4589 - accuracy: 0.8447\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1888 - accuracy: 0.9384\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1330 - accuracy: 0.9555\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=3, n_neurons=128, optimizer=adam; total time=  15.7s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.4379 - accuracy: 0.8541\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1865 - accuracy: 0.9404\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1343 - accuracy: 0.9559\n",
      "530/530 [==============================] - 1s 1ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=3, n_neurons=128, optimizer=adam; total time=  15.3s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.4021 - accuracy: 0.8632\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1734 - accuracy: 0.9423\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1227 - accuracy: 0.9575\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=3, n_neurons=192, optimizer=adam; total time=  20.3s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.4128 - accuracy: 0.8605\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1719 - accuracy: 0.9425\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1151 - accuracy: 0.9606\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=3, n_neurons=192, optimizer=adam; total time=  19.3s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.4065 - accuracy: 0.8637\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1729 - accuracy: 0.9434\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1222 - accuracy: 0.9581\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=3, n_neurons=192, optimizer=adam; total time=  20.1s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.3832 - accuracy: 0.8756\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1651 - accuracy: 0.9457\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.1168 - accuracy: 0.9597\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=3, n_neurons=256, optimizer=adam; total time=  27.6s\n",
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.3868 - accuracy: 0.8712\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1659 - accuracy: 0.9473\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1121 - accuracy: 0.9623\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=3, n_neurons=256, optimizer=adam; total time=  29.1s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.3789 - accuracy: 0.8720\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.1663 - accuracy: 0.9443\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1167 - accuracy: 0.9608\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=3, n_neurons=256, optimizer=adam; total time=  27.5s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.4513 - accuracy: 0.8489\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1929 - accuracy: 0.9395\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1343 - accuracy: 0.9571\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1058 - accuracy: 0.9648\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0863 - accuracy: 0.9719\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0684 - accuracy: 0.9766\n",
      "530/530 [==============================] - 1s 1ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=6, n_neurons=128, optimizer=adam; total time=  26.5s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.4638 - accuracy: 0.8494\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1844 - accuracy: 0.9426\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1321 - accuracy: 0.9572\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1022 - accuracy: 0.9655\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0794 - accuracy: 0.9744\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0723 - accuracy: 0.9752\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=6, n_neurons=128, optimizer=adam; total time=  30.5s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.4485 - accuracy: 0.8510\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1856 - accuracy: 0.9389\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1403 - accuracy: 0.9538\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1032 - accuracy: 0.9660\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0893 - accuracy: 0.9699\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0757 - accuracy: 0.9740\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=6, n_neurons=128, optimizer=adam; total time=  30.1s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.4163 - accuracy: 0.8630\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1772 - accuracy: 0.9435\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1212 - accuracy: 0.9581\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0919 - accuracy: 0.9687\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0744 - accuracy: 0.9739\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0661 - accuracy: 0.9776\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=6, n_neurons=192, optimizer=adam; total time=  38.5s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.4069 - accuracy: 0.8626\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1699 - accuracy: 0.9445\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1225 - accuracy: 0.9575\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0901 - accuracy: 0.9688\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0756 - accuracy: 0.9733\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0631 - accuracy: 0.9774\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=6, n_neurons=192, optimizer=adam; total time=  40.0s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 8s 6ms/step - loss: 0.4101 - accuracy: 0.8648\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1721 - accuracy: 0.9443\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1243 - accuracy: 0.9579\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0945 - accuracy: 0.9661\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0730 - accuracy: 0.9738\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0646 - accuracy: 0.9777\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=6, n_neurons=192, optimizer=adam; total time=  39.0s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 10s 9ms/step - loss: 0.3794 - accuracy: 0.8753\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.1665 - accuracy: 0.9445\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 9s 9ms/step - loss: 0.1114 - accuracy: 0.9623\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.0903 - accuracy: 0.9685\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0688 - accuracy: 0.9743\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0602 - accuracy: 0.9778\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=6, n_neurons=256, optimizer=adam; total time=  55.9s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.3773 - accuracy: 0.8757\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 9s 9ms/step - loss: 0.1656 - accuracy: 0.9461\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 9s 9ms/step - loss: 0.1171 - accuracy: 0.9606\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 10s 9ms/step - loss: 0.0858 - accuracy: 0.9692\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0660 - accuracy: 0.9782\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0559 - accuracy: 0.9809\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=6, n_neurons=256, optimizer=adam; total time=  57.5s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 9s 7ms/step - loss: 0.3771 - accuracy: 0.8747\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.1692 - accuracy: 0.9446\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 9s 9ms/step - loss: 0.1155 - accuracy: 0.9590\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 10s 9ms/step - loss: 0.0947 - accuracy: 0.9666\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.0711 - accuracy: 0.9746\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0606 - accuracy: 0.9787\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=6, n_neurons=256, optimizer=adam; total time=  58.3s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.4333 - accuracy: 0.8578\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1871 - accuracy: 0.9407\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1336 - accuracy: 0.9567\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1034 - accuracy: 0.9642\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0859 - accuracy: 0.9716\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0678 - accuracy: 0.9768\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0591 - accuracy: 0.9800\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0523 - accuracy: 0.9813\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0504 - accuracy: 0.9831\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0370 - accuracy: 0.9871\n",
      "530/530 [==============================] - 1s 1ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=10, n_neurons=128, optimizer=adam; total time=  43.6s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 11s 4ms/step - loss: 0.4759 - accuracy: 0.8410\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1877 - accuracy: 0.9406\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1316 - accuracy: 0.9572\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1031 - accuracy: 0.9664\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0804 - accuracy: 0.9731\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0689 - accuracy: 0.9767\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0614 - accuracy: 0.9793\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0509 - accuracy: 0.9831\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0429 - accuracy: 0.9856\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0368 - accuracy: 0.9861\n",
      "530/530 [==============================] - 1s 1ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=10, n_neurons=128, optimizer=adam; total time=  50.9s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.4675 - accuracy: 0.8387\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1891 - accuracy: 0.9399\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1376 - accuracy: 0.9539\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1093 - accuracy: 0.9637\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0836 - accuracy: 0.9717\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0705 - accuracy: 0.9753\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0607 - accuracy: 0.9781\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0523 - accuracy: 0.9815\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0475 - accuracy: 0.9836\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.0407 - accuracy: 0.9862\n",
      "530/530 [==============================] - 1s 1ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=10, n_neurons=128, optimizer=adam; total time=  41.0s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.4032 - accuracy: 0.8599\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1726 - accuracy: 0.9437\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1198 - accuracy: 0.9603\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0939 - accuracy: 0.9669\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0776 - accuracy: 0.9726\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0627 - accuracy: 0.9784\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0529 - accuracy: 0.9823\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0446 - accuracy: 0.9838\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0427 - accuracy: 0.9858\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0389 - accuracy: 0.9863\n",
      "530/530 [==============================] - 1s 3ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=10, n_neurons=192, optimizer=adam; total time=  59.4s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.4184 - accuracy: 0.8586\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1661 - accuracy: 0.9454\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1225 - accuracy: 0.9595\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0971 - accuracy: 0.9665\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0732 - accuracy: 0.9744\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0635 - accuracy: 0.9784\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0501 - accuracy: 0.9813\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0440 - accuracy: 0.9854\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0429 - accuracy: 0.9855\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0359 - accuracy: 0.9879\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=10, n_neurons=192, optimizer=adam; total time=  57.3s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.4243 - accuracy: 0.8545\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1723 - accuracy: 0.9434\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1243 - accuracy: 0.9578\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0936 - accuracy: 0.9662\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0761 - accuracy: 0.9732\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0660 - accuracy: 0.9766\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0551 - accuracy: 0.9792\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0499 - accuracy: 0.9831\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0404 - accuracy: 0.9855\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0378 - accuracy: 0.9871\n",
      "530/530 [==============================] - 2s 3ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=10, n_neurons=192, optimizer=adam; total time= 1.1min\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 10s 9ms/step - loss: 0.3914 - accuracy: 0.8700\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 9s 9ms/step - loss: 0.1639 - accuracy: 0.9476\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.1178 - accuracy: 0.9574\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0880 - accuracy: 0.9689\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0696 - accuracy: 0.9747\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0556 - accuracy: 0.9800\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0501 - accuracy: 0.9830\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0446 - accuracy: 0.9838\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 9s 9ms/step - loss: 0.0367 - accuracy: 0.9862\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 9s 9ms/step - loss: 0.0329 - accuracy: 0.9884\n",
      "530/530 [==============================] - 1s 3ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=10, n_neurons=256, optimizer=adam; total time= 1.5min\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 12s 10ms/step - loss: 0.3777 - accuracy: 0.8746\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.1645 - accuracy: 0.9477\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1132 - accuracy: 0.9613\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.0879 - accuracy: 0.9693\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0718 - accuracy: 0.9732\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0627 - accuracy: 0.9787\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0504 - accuracy: 0.9829\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0410 - accuracy: 0.9854\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0362 - accuracy: 0.9874\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0341 - accuracy: 0.9885\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=10, n_neurons=256, optimizer=adam; total time= 1.5min\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.3847 - accuracy: 0.8729\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.1648 - accuracy: 0.9451\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.1204 - accuracy: 0.9586\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0886 - accuracy: 0.9672\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0717 - accuracy: 0.9744\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0603 - accuracy: 0.9787\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0500 - accuracy: 0.9827\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0451 - accuracy: 0.9838\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.0362 - accuracy: 0.9874\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 11s 10ms/step - loss: 0.0375 - accuracy: 0.9859\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.4, epochs=10, n_neurons=256, optimizer=adam; total time= 1.5min\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.6365 - accuracy: 0.7736\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2759 - accuracy: 0.9150\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.2172 - accuracy: 0.9333\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=3, n_neurons=128, optimizer=adam; total time=  19.4s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.6334 - accuracy: 0.7756\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2799 - accuracy: 0.9145\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.2199 - accuracy: 0.9326\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=3, n_neurons=128, optimizer=adam; total time=  26.0s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.6724 - accuracy: 0.7718\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2856 - accuracy: 0.9140\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2177 - accuracy: 0.9338\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=3, n_neurons=128, optimizer=adam; total time=  18.1s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 8s 6ms/step - loss: 0.5467 - accuracy: 0.8131\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.2361 - accuracy: 0.9265\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1874 - accuracy: 0.9417\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=3, n_neurons=192, optimizer=adam; total time=  21.9s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.5417 - accuracy: 0.8098\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.2373 - accuracy: 0.9261\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1789 - accuracy: 0.9434\n",
      "530/530 [==============================] - 2s 3ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=3, n_neurons=192, optimizer=adam; total time=  22.5s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 7s 5ms/step - loss: 0.5289 - accuracy: 0.8187\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.2386 - accuracy: 0.9258\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1849 - accuracy: 0.9408\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=3, n_neurons=192, optimizer=adam; total time=  22.4s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 10s 8ms/step - loss: 0.4910 - accuracy: 0.8310\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 10s 9ms/step - loss: 0.2222 - accuracy: 0.9303\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 10s 9ms/step - loss: 0.1735 - accuracy: 0.9463\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=3, n_neurons=256, optimizer=adam; total time=  45.8s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.4862 - accuracy: 0.8335\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.2205 - accuracy: 0.9307\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.1705 - accuracy: 0.9470\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=3, n_neurons=256, optimizer=adam; total time=  26.1s\n",
      "Epoch 1/3\n",
      "1059/1059 [==============================] - 9s 7ms/step - loss: 0.4712 - accuracy: 0.8391\n",
      "Epoch 2/3\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.2254 - accuracy: 0.9285\n",
      "Epoch 3/3\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.1762 - accuracy: 0.9433\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=3, n_neurons=256, optimizer=adam; total time=  45.5s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.6458 - accuracy: 0.7698\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2730 - accuracy: 0.9179\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.2203 - accuracy: 0.9328\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1801 - accuracy: 0.9441\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.1549 - accuracy: 0.9522\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.1407 - accuracy: 0.9544\n",
      "530/530 [==============================] - 1s 1ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=6, n_neurons=128, optimizer=adam; total time=  26.0s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.6337 - accuracy: 0.7811\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2728 - accuracy: 0.9165\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2126 - accuracy: 0.9363\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1805 - accuracy: 0.9437\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1571 - accuracy: 0.9503\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1403 - accuracy: 0.9547\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=6, n_neurons=128, optimizer=adam; total time=  28.7s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.6568 - accuracy: 0.7619\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2791 - accuracy: 0.9132\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.2187 - accuracy: 0.9323\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1842 - accuracy: 0.9423\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.1641 - accuracy: 0.9487\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.1377 - accuracy: 0.9545\n",
      "530/530 [==============================] - 1s 1ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=6, n_neurons=128, optimizer=adam; total time=  26.2s\n",
      "Epoch 1/6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.5309 - accuracy: 0.8175\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.2371 - accuracy: 0.9251\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1887 - accuracy: 0.9425\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1563 - accuracy: 0.9512\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1313 - accuracy: 0.9571\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1170 - accuracy: 0.9617\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=6, n_neurons=192, optimizer=adam; total time=  34.6s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.5391 - accuracy: 0.8155\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.2335 - accuracy: 0.9293\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1831 - accuracy: 0.9431\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1506 - accuracy: 0.9520\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1277 - accuracy: 0.9587\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1121 - accuracy: 0.9634\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=6, n_neurons=192, optimizer=adam; total time=  36.8s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.5325 - accuracy: 0.8128\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.2382 - accuracy: 0.9274\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1841 - accuracy: 0.9429\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1518 - accuracy: 0.9499\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1310 - accuracy: 0.9570\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1171 - accuracy: 0.9626\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=6, n_neurons=192, optimizer=adam; total time=  37.3s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.4748 - accuracy: 0.8356\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.2229 - accuracy: 0.9290\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.1742 - accuracy: 0.9435\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.1439 - accuracy: 0.9541\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.1252 - accuracy: 0.9574\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.1044 - accuracy: 0.9646\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=6, n_neurons=256, optimizer=adam; total time=  51.4s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.4945 - accuracy: 0.8279\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.2212 - accuracy: 0.9301\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.1716 - accuracy: 0.9460\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.1353 - accuracy: 0.9564\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.1188 - accuracy: 0.9613\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1086 - accuracy: 0.9656\n",
      "530/530 [==============================] - 2s 3ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=6, n_neurons=256, optimizer=adam; total time=  54.2s\n",
      "Epoch 1/6\n",
      "1059/1059 [==============================] - 9s 7ms/step - loss: 0.4835 - accuracy: 0.8370\n",
      "Epoch 2/6\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.2190 - accuracy: 0.9291\n",
      "Epoch 3/6\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.1710 - accuracy: 0.9454\n",
      "Epoch 4/6\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1434 - accuracy: 0.9526\n",
      "Epoch 5/6\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.1255 - accuracy: 0.9593\n",
      "Epoch 6/6\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.1079 - accuracy: 0.9643\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=6, n_neurons=256, optimizer=adam; total time= 1.4min\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.6460 - accuracy: 0.7731\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2858 - accuracy: 0.9119\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2180 - accuracy: 0.9334\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.1819 - accuracy: 0.9444\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1544 - accuracy: 0.9519\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1388 - accuracy: 0.9552\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1238 - accuracy: 0.9604\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1118 - accuracy: 0.9626\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.1018 - accuracy: 0.9671\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.0956 - accuracy: 0.9702\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=10, n_neurons=128, optimizer=adam; total time=  45.8s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.6189 - accuracy: 0.7839\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2739 - accuracy: 0.9154\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.2144 - accuracy: 0.9348\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.1760 - accuracy: 0.9435\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.1547 - accuracy: 0.9507\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1363 - accuracy: 0.9569\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.1254 - accuracy: 0.9601\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.1148 - accuracy: 0.9623\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1019 - accuracy: 0.9677\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.0970 - accuracy: 0.9686\n",
      "530/530 [==============================] - 1s 1ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=10, n_neurons=128, optimizer=adam; total time=  41.2s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.6087 - accuracy: 0.7858\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.2765 - accuracy: 0.9133\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.2211 - accuracy: 0.9316\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1836 - accuracy: 0.9466\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1579 - accuracy: 0.9505\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1402 - accuracy: 0.9554\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.1315 - accuracy: 0.9571\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 4s 3ms/step - loss: 0.1191 - accuracy: 0.9616\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 4s 4ms/step - loss: 0.1093 - accuracy: 0.9649\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 5s 4ms/step - loss: 0.0985 - accuracy: 0.9666\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=10, n_neurons=128, optimizer=adam; total time=  54.4s\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.5401 - accuracy: 0.8166\n",
      "Epoch 2/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.2378 - accuracy: 0.9259\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1896 - accuracy: 0.9398\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1543 - accuracy: 0.9506\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.1343 - accuracy: 0.9570\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.1167 - accuracy: 0.9617\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1056 - accuracy: 0.9663\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.0929 - accuracy: 0.9704\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.0889 - accuracy: 0.9711\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0814 - accuracy: 0.9718\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=10, n_neurons=192, optimizer=adam; total time= 1.2min\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.5482 - accuracy: 0.8130\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.2419 - accuracy: 0.9260\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.1824 - accuracy: 0.9437\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1546 - accuracy: 0.9497\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1345 - accuracy: 0.9557\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.1176 - accuracy: 0.9621\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.1022 - accuracy: 0.9654\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0911 - accuracy: 0.9699\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0841 - accuracy: 0.9714\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0811 - accuracy: 0.9730\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=10, n_neurons=192, optimizer=adam; total time= 1.0min\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.5273 - accuracy: 0.8248\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.2347 - accuracy: 0.9256\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.1828 - accuracy: 0.9437\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.1525 - accuracy: 0.9513\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1320 - accuracy: 0.9573\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 6s 6ms/step - loss: 0.1156 - accuracy: 0.9610\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 7s 6ms/step - loss: 0.1032 - accuracy: 0.9653\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0944 - accuracy: 0.9684\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 6s 5ms/step - loss: 0.0885 - accuracy: 0.9707\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 5s 5ms/step - loss: 0.0779 - accuracy: 0.9735\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=10, n_neurons=192, optimizer=adam; total time= 1.1min\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 10s 9ms/step - loss: 0.4786 - accuracy: 0.8384\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 10s 9ms/step - loss: 0.2188 - accuracy: 0.9326\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.1739 - accuracy: 0.9434\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.1408 - accuracy: 0.9537\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 10s 10ms/step - loss: 0.1215 - accuracy: 0.9594\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 13s 12ms/step - loss: 0.1043 - accuracy: 0.9640\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 10s 9ms/step - loss: 0.0906 - accuracy: 0.9688\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.0872 - accuracy: 0.9700\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.0744 - accuracy: 0.9745\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 9s 9ms/step - loss: 0.0716 - accuracy: 0.9754\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=10, n_neurons=256, optimizer=adam; total time= 1.7min\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.4793 - accuracy: 0.8346\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.2191 - accuracy: 0.9317\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1682 - accuracy: 0.9470\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1420 - accuracy: 0.9523\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1268 - accuracy: 0.9600\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 8s 7ms/step - loss: 0.1019 - accuracy: 0.9661\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 12s 12ms/step - loss: 0.0960 - accuracy: 0.9683\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 11s 10ms/step - loss: 0.0819 - accuracy: 0.9728\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 10s 9ms/step - loss: 0.0767 - accuracy: 0.9729\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.0717 - accuracy: 0.9770\n",
      "530/530 [==============================] - 1s 2ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=10, n_neurons=256, optimizer=adam; total time= 1.6min\n",
      "Epoch 1/10\n",
      "1059/1059 [==============================] - 11s 9ms/step - loss: 0.4834 - accuracy: 0.8319\n",
      "Epoch 2/10\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.2239 - accuracy: 0.9289\n",
      "Epoch 3/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.1668 - accuracy: 0.9460\n",
      "Epoch 4/10\n",
      "1059/1059 [==============================] - 9s 8ms/step - loss: 0.1457 - accuracy: 0.9532\n",
      "Epoch 5/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.1293 - accuracy: 0.9582\n",
      "Epoch 6/10\n",
      "1059/1059 [==============================] - 9s 9ms/step - loss: 0.1072 - accuracy: 0.9649\n",
      "Epoch 7/10\n",
      "1059/1059 [==============================] - 8s 8ms/step - loss: 0.0912 - accuracy: 0.9684\n",
      "Epoch 8/10\n",
      "1059/1059 [==============================] - 9s 9ms/step - loss: 0.0821 - accuracy: 0.9718\n",
      "Epoch 9/10\n",
      "1059/1059 [==============================] - 7s 7ms/step - loss: 0.0777 - accuracy: 0.9728\n",
      "Epoch 10/10\n",
      "1059/1059 [==============================] - 11s 10ms/step - loss: 0.0807 - accuracy: 0.9736\n",
      "530/530 [==============================] - 1s 3ms/step\n",
      "[CV] END batch_size=16, dp=0.6, epochs=10, n_neurons=256, optimizer=adam; total time= 1.6min\n",
      "Epoch 1/10\n",
      "1588/1588 [==============================] - 11s 6ms/step - loss: 0.4725 - accuracy: 0.8406\n",
      "Epoch 2/10\n",
      "1588/1588 [==============================] - 10s 6ms/step - loss: 0.2213 - accuracy: 0.9309\n",
      "Epoch 3/10\n",
      "1588/1588 [==============================] - 10s 6ms/step - loss: 0.1855 - accuracy: 0.9432\n",
      "Epoch 4/10\n",
      "1588/1588 [==============================] - 9s 6ms/step - loss: 0.1587 - accuracy: 0.9491\n",
      "Epoch 5/10\n",
      "1588/1588 [==============================] - 9s 5ms/step - loss: 0.1419 - accuracy: 0.9531\n",
      "Epoch 6/10\n",
      "1588/1588 [==============================] - 8s 5ms/step - loss: 0.1257 - accuracy: 0.9584\n",
      "Epoch 7/10\n",
      "1588/1588 [==============================] - 8s 5ms/step - loss: 0.1144 - accuracy: 0.9620\n",
      "Epoch 8/10\n",
      "1588/1588 [==============================] - 9s 6ms/step - loss: 0.1042 - accuracy: 0.9654\n",
      "Epoch 9/10\n",
      "1588/1588 [==============================] - 9s 5ms/step - loss: 0.0931 - accuracy: 0.9682\n",
      "Epoch 10/10\n",
      "1588/1588 [==============================] - 8s 5ms/step - loss: 0.0874 - accuracy: 0.9711\n"
     ]
    }
   ],
   "source": [
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "ec496953",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dp</th>\n",
       "      <th>epochs</th>\n",
       "      <th>n_neurons</th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std. Dev</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>192</td>\n",
       "      <td>93.3976</td>\n",
       "      <td>0.207484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>93.3662</td>\n",
       "      <td>0.230753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>192</td>\n",
       "      <td>93.3622</td>\n",
       "      <td>0.075154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>93.3465</td>\n",
       "      <td>0.154075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>93.3386</td>\n",
       "      <td>0.105761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>256</td>\n",
       "      <td>93.3268</td>\n",
       "      <td>0.352725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>192</td>\n",
       "      <td>93.3268</td>\n",
       "      <td>0.057542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.6</td>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>93.2874</td>\n",
       "      <td>0.206028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.6</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>93.2480</td>\n",
       "      <td>0.184312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.6</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>93.2165</td>\n",
       "      <td>0.155946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>128</td>\n",
       "      <td>93.1496</td>\n",
       "      <td>0.086465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>93.0945</td>\n",
       "      <td>0.198523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.4</td>\n",
       "      <td>6</td>\n",
       "      <td>192</td>\n",
       "      <td>93.0276</td>\n",
       "      <td>0.022079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>192</td>\n",
       "      <td>93.0000</td>\n",
       "      <td>0.237690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>92.9764</td>\n",
       "      <td>0.109951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>92.9646</td>\n",
       "      <td>0.149537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.4</td>\n",
       "      <td>10</td>\n",
       "      <td>192</td>\n",
       "      <td>92.9528</td>\n",
       "      <td>0.123617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.4</td>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>92.9370</td>\n",
       "      <td>0.109145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.4</td>\n",
       "      <td>6</td>\n",
       "      <td>256</td>\n",
       "      <td>92.8622</td>\n",
       "      <td>0.068063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.4</td>\n",
       "      <td>3</td>\n",
       "      <td>256</td>\n",
       "      <td>92.8504</td>\n",
       "      <td>0.171585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>192</td>\n",
       "      <td>92.8189</td>\n",
       "      <td>0.271695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>128</td>\n",
       "      <td>92.7402</td>\n",
       "      <td>0.269879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>192</td>\n",
       "      <td>92.7165</td>\n",
       "      <td>0.258555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>256</td>\n",
       "      <td>92.6181</td>\n",
       "      <td>0.197847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>128</td>\n",
       "      <td>92.6024</td>\n",
       "      <td>0.271513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.2</td>\n",
       "      <td>10</td>\n",
       "      <td>192</td>\n",
       "      <td>92.4528</td>\n",
       "      <td>0.170228</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.2</td>\n",
       "      <td>6</td>\n",
       "      <td>256</td>\n",
       "      <td>92.4449</td>\n",
       "      <td>0.200110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     dp  epochs  n_neurons     Mean  Std. Dev\n",
       "25  0.6      10        192  93.3976  0.207484\n",
       "24  0.6      10        128  93.3662  0.230753\n",
       "19  0.6       3        192  93.3622  0.075154\n",
       "9   0.4       3        128  93.3465  0.154075\n",
       "20  0.6       3        256  93.3386  0.105761\n",
       "23  0.6       6        256  93.3268  0.352725\n",
       "22  0.6       6        192  93.3268  0.057542\n",
       "21  0.6       6        128  93.2874  0.206028\n",
       "26  0.6      10        256  93.2480  0.184312\n",
       "18  0.6       3        128  93.2165  0.155946\n",
       "0   0.2       3        128  93.1496  0.086465\n",
       "15  0.4      10        128  93.0945  0.198523\n",
       "13  0.4       6        192  93.0276  0.022079\n",
       "10  0.4       3        192  93.0000  0.237690\n",
       "2   0.2       3        256  92.9764  0.109951\n",
       "17  0.4      10        256  92.9646  0.149537\n",
       "16  0.4      10        192  92.9528  0.123617\n",
       "12  0.4       6        128  92.9370  0.109145\n",
       "14  0.4       6        256  92.8622  0.068063\n",
       "11  0.4       3        256  92.8504  0.171585\n",
       "1   0.2       3        192  92.8189  0.271695\n",
       "3   0.2       6        128  92.7402  0.269879\n",
       "4   0.2       6        192  92.7165  0.258555\n",
       "8   0.2      10        256  92.6181  0.197847\n",
       "6   0.2      10        128  92.6024  0.271513\n",
       "7   0.2      10        192  92.4528  0.170228\n",
       "5   0.2       6        256  92.4449  0.200110"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "means = np.round(100*grid_result.cv_results_['mean_test_score'], 4)\n",
    "stds = 100*grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "\n",
    "d = pd.DataFrame(params)\n",
    "d['Mean'] = means\n",
    "d['Std. Dev'] = stds\n",
    "\n",
    "d.sort_values(\"Mean\", ascending=False).drop(columns=[\"batch_size\", \"optimizer\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2e615a5",
   "metadata": {},
   "source": [
    "**Classification Report on test data:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "b1130ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "397/397 [==============================] - 1s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.97      0.97       744\n",
      "           1       0.92      0.93      0.92      1508\n",
      "           2       0.97      0.97      0.97       719\n",
      "           3       0.82      0.86      0.84       765\n",
      "           4       0.96      0.94      0.95      1093\n",
      "           5       0.97      0.96      0.97      1522\n",
      "\n",
      "    accuracy                           0.94      6351\n",
      "   macro avg       0.94      0.94      0.94      6351\n",
      "weighted avg       0.94      0.94      0.94      6351\n",
      "\n",
      "Accuracy on test: 93.92\n"
     ]
    }
   ],
   "source": [
    "preds = grid.predict(X_test)\n",
    "# Classification report\n",
    "report = classification_report(y_test.argmax(axis=1), preds.argmax(axis=1))\n",
    "print(report)\n",
    "\n",
    "print('Accuracy on test: %.2f' % round(100*accuracy_score(y_test, preds), 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca37e3",
   "metadata": {},
   "source": [
    "### Before we continue, let's train this model on all data and save a prediction in the test set, in case this will be one of our final models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "07d38b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cakes_cupcakes_snack_cakes': 0, 'candy': 1, 'chips_pretzels_snacks': 2, 'chocolate': 3, 'cookies_biscuits': 4, 'popcorn_peanuts_seeds_related_snacks': 5}\n",
      "Train:\n",
      "\ttrain_data: (31751, 16444) of float32\n",
      "\ty: (31751, 6) of float32\n",
      "Test:\n",
      "\ttest_data: (3525, 16444) of float32\n"
     ]
    }
   ],
   "source": [
    "train_data, y = load_train_data()\n",
    "train_data, _, test_data = prepare_inputs(train_data, train_data, has_valid=False)\n",
    "\n",
    "y, _ = prepare_targets(y, y, has_valid=False)\n",
    "\n",
    "print(\"Train:\")\n",
    "print(f'\\ttrain_data: {train_data.shape} of {train_data.dtype}')\n",
    "print(f'\\ty: {y.shape} of {y.dtype}')\n",
    "print(\"Test:\")\n",
    "print(f'\\ttest_data: {test_data.shape} of {test_data.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "a7839f18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16,\n",
       " 'dp': 0.6,\n",
       " 'epochs': 10,\n",
       " 'n_neurons': 192,\n",
       " 'optimizer': 'adam'}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "15684025",
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1985/1985 - 9s - loss: 0.4076 - accuracy: 0.8657 - 9s/epoch - 5ms/step\n",
      "Epoch 2/10\n",
      "1985/1985 - 10s - loss: 0.2203 - accuracy: 0.9329 - 10s/epoch - 5ms/step\n",
      "Epoch 3/10\n",
      "1985/1985 - 10s - loss: 0.1835 - accuracy: 0.9415 - 10s/epoch - 5ms/step\n",
      "Epoch 4/10\n",
      "1985/1985 - 10s - loss: 0.1581 - accuracy: 0.9497 - 10s/epoch - 5ms/step\n",
      "Epoch 5/10\n",
      "1985/1985 - 10s - loss: 0.1394 - accuracy: 0.9561 - 10s/epoch - 5ms/step\n",
      "Epoch 6/10\n",
      "1985/1985 - 10s - loss: 0.1294 - accuracy: 0.9586 - 10s/epoch - 5ms/step\n",
      "Epoch 7/10\n",
      "1985/1985 - 11s - loss: 0.1158 - accuracy: 0.9622 - 11s/epoch - 5ms/step\n",
      "Epoch 8/10\n",
      "1985/1985 - 11s - loss: 0.1055 - accuracy: 0.9654 - 11s/epoch - 6ms/step\n",
      "Epoch 9/10\n",
      "1985/1985 - 11s - loss: 0.0957 - accuracy: 0.9682 - 11s/epoch - 5ms/step\n",
      "Epoch 10/10\n",
      "1985/1985 - 11s - loss: 0.0891 - accuracy: 0.9705 - 11s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Fit model on all train data\n",
    "INPUT_SHAPE = train_data.shape[1]\n",
    "model_CV_2 = create_model_cv(\n",
    "    dp=0.6, \n",
    "    optimizer='adam',  \n",
    "    n_neurons=192\n",
    ")\n",
    "history = model_CV_2.fit(\n",
    "    train_data,\n",
    "    y,\n",
    "    epochs=10,\n",
    "    batch_size=16,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "b4b5b770",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 16,\n",
       " 'dp': 0.6,\n",
       " 'init': 'glorot_uniform',\n",
       " 'n_neurons': 256,\n",
       " 'optimizer': 'rmsprop'}"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b30f1fb",
   "metadata": {},
   "source": [
    "#### Sanity check on train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "7cb46e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "993/993 [==============================] - 2s 2ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3786\n",
      "           1       0.99      0.95      0.97      7584\n",
      "           2       0.99      1.00      1.00      3680\n",
      "           3       0.90      0.98      0.94      3772\n",
      "           4       0.99      0.99      0.99      5284\n",
      "           5       1.00      0.99      0.99      7645\n",
      "\n",
      "    accuracy                           0.98     31751\n",
      "   macro avg       0.98      0.99      0.98     31751\n",
      "weighted avg       0.98      0.98      0.98     31751\n",
      "\n",
      "Accuracy on train: 98.23\n"
     ]
    }
   ],
   "source": [
    "preds = model_CV_2.predict(train_data)\n",
    "# Classification report\n",
    "print(classification_report(y.argmax(axis=1), preds.argmax(axis=1)))\n",
    "accuracy = sum(preds.argmax(axis=1) == y.argmax(axis=1)) / len(preds)\n",
    "print('Accuracy on train: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ef1cc2",
   "metadata": {},
   "source": [
    "#### Predict on test data and save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "f68361e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "111/111 [==============================] - 0s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "preds = model_CV_2.predict(test_data).argmax(axis=1)\n",
    "preds = [mapping[i] for i in preds]\n",
    "test_indexes = load_test_data().idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "0170fc19",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_model_02 = pd.DataFrame({\"idx\": indexes, \"pred_cat\": preds})\n",
    "results_model_02.to_csv(\"model_02.csv\", index=False)\n",
    "\n",
    "# For sanity check\n",
    "t = load_test_data()\n",
    "t[\"pred_cat\"] = preds\n",
    "t.to_csv(\"model_02_check.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da7077",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "Well, seems like the different hyperparameters don't affect that much the network's performance, as we see the accuracy for all of them is not very different, and there's no clear answer whether it improved the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27bee57",
   "metadata": {},
   "source": [
    "## Adding the predictions from our CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ac9505",
   "metadata": {},
   "source": [
    "We decided to seperatly train our CNN on the images, and add its predictions as another feature for our tabular data.\n",
    "We understand that its both not the most correct and elegant way to combine them, and the better way would be to combine 2 networks together and add some dense layers after that, and also that it might cause us to overfit on the training data.\n",
    "We chose this way beacuse of time constrains - we tried buiding a combined NN but we got a little bit confused and things didn't work for us.\n",
    "We'll be hyper aware of overfitting when we check if this new feature is helpful :)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bcf6d2",
   "metadata": {},
   "source": [
    "First step we did was add the \"with_cnn\" flag to all relevant functions, so that if we choose to add this feature to the model, we'll be able to.\n",
    "\n",
    "But, in order to fairly check whether this feature improves the model, we did the following:\n",
    "- Trained the CNN on 70% of the data, left 30% for test.\n",
    "- Saved the indexes we used for test, and seperated our tabular data exactly the same - so we won't predict on products which their image we used as a training image.\n",
    "\n",
    "Therefore, the following code is to manually create these dfs. It's a bit messy and we apologize for it :). If we had more time we would better integrate this as part of the already created functions.\n",
    "\n",
    "(Code is hidden, appears in the notebook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "c0297e02",
   "metadata": {
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [],
   "source": [
    "# Read test indexes\n",
    "indexes_valid_images = pd.read_csv(\"./valid_images_indexes.csv\").image.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "719b2c3e",
   "metadata": {
    "tags": [
     "hide_code"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'cakes_cupcakes_snack_cakes': 0, 'candy': 1, 'chips_pretzels_snacks': 2, 'chocolate': 3, 'cookies_biscuits': 4, 'popcorn_peanuts_seeds_related_snacks': 5}\n"
     ]
    }
   ],
   "source": [
    "# Get data (Manually, as we need the specific indexes we used as validation data in the CNN)\n",
    "\n",
    "df = prepare_unified_df(test=False)\n",
    "# Add cnn predictions as feature\n",
    "cnn_df = pd.DataFrame()\n",
    "for category_name in mapping.values():\n",
    "    tmp_df = pd.read_csv(f\"./cnn_predictions/{category_name}.csv\")\n",
    "    cnn_df = pd.concat([cnn_df, tmp_df])\n",
    "cnn_df = cnn_df.astype(int)\n",
    "cnn_df = cnn_df.sort_values('img', ignore_index=True)\n",
    "cnn_df = cnn_df.rename(columns={\"prediction\": \"cnn_prediction\"})\n",
    "df = df.merge(cnn_df, left_on=\"idx\", right_on=\"img\")\n",
    "df[\"cnn_prediction\"] = df.cnn_prediction.apply(lambda x: mapping[x])\n",
    "\n",
    "# Seperate df to train and test according to our indexes\n",
    "df_test = df.loc[df['idx'].isin(indexes_valid_images)]\n",
    "df_train = df.loc[~df['idx'].isin(indexes_valid_images)]\n",
    "\n",
    "# Seperate to X and y for train and test\n",
    "X_train = df_train.drop([\"category\"], axis=1)\n",
    "X_test = df_test.drop([\"category\"], axis=1)\n",
    "y_train = df_train[\"category\"]\n",
    "y_test = df_test[\"category\"]\n",
    "\n",
    "# Prepare X data\n",
    "preprocessed_X_train = preprocess(X_train, with_cnn=True)\n",
    "preprocessed_X_test = preprocess(X_test, with_cnn=True)\n",
    "preprocessed_X_train = add_num_of_ings_col(preprocessed_X_train)\n",
    "preprocessed_X_test = add_num_of_ings_col(preprocessed_X_test)\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(preprocessed_X_train.serving_size.values.reshape(-1, 1))\n",
    "preprocessed_X_train[\"serving_size\"] = scaler.transform(preprocessed_X_train.serving_size.values.reshape(-1, 1))\n",
    "preprocessed_X_test[\"serving_size\"] = scaler.transform(preprocessed_X_test.serving_size.values.reshape(-1, 1))\n",
    "vectorizer_cnn = create_vectorizer(with_cnn=True)\n",
    "X_train_cnn = vectorizer_cnn.fit_transform(preprocessed_X_train).astype(np.float32).toarray()\n",
    "X_test_cnn = vectorizer_cnn.transform(preprocessed_X_test).astype(np.float32).toarray()\n",
    "\n",
    "X_valid_cnn = X_test_cnn[0:3174]\n",
    "X_test_cnn = X_test_cnn[3174:]\n",
    "\n",
    "# Prepate y data\n",
    "y_train_cnn, y_test_cnn = prepare_targets(y_train, y_test, has_valid=False)\n",
    "y_valid_cnn = y_test_cnn[0:3174]\n",
    "y_test_cnn = y_test_cnn[3174:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "4aa6e73b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "\tX_train_cnn: (22228, 16442) of float32\n",
      "\ty_train_cnn: (22228, 6) of float32\n",
      "Validation:\n",
      "\tX_valid_cnn: (3174, 16442) of float32\n",
      "\ty_valid_cnn: (3174, 6) of float32\n",
      "Test:\n",
      "\tX_test_cnn: (6349, 16442) of float32\n",
      "\ty_test_cnn: (6349, 6) of float32\n"
     ]
    }
   ],
   "source": [
    "# Sanity check\n",
    "print(\"Train:\")\n",
    "print(f'\\tX_train_cnn: {X_train_cnn.shape} of {X_train_cnn.dtype}')\n",
    "print(f'\\ty_train_cnn: {y_train_cnn.shape} of {y_train_cnn.dtype}')\n",
    "print(\"Validation:\")\n",
    "print(f'\\tX_valid_cnn: {X_valid_cnn.shape} of {X_valid_cnn.dtype}')\n",
    "print(f'\\ty_valid_cnn: {y_valid_cnn.shape} of {y_valid_cnn.dtype}')\n",
    "print(\"Test:\")\n",
    "print(f'\\tX_test_cnn: {X_test_cnn.shape} of {X_test_cnn.dtype}')\n",
    "print(f'\\ty_test_cnn: {y_test_cnn.shape} of {y_test_cnn.dtype}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "ae3de8aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping callback\n",
    "es_cnn = keras.callbacks.EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=15,  # stop training when there's no improvement in val_loss for 15 consecutive epochs\n",
    "    restore_best_weights=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "6804667f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same model we used in our first model\n",
    "def create_model_cnn(dp=0.4, optimizer='adam', num_nuerons=[128, 32, 16]):\n",
    "    model_in = ks.Input(shape=(INPUT_SHAPE,), dtype='float32', sparse=True)\n",
    "    out = ks.layers.Dense(num_nuerons[0], activation='relu')(model_in)\n",
    "    out = ks.layers.Dropout(dp)(out)\n",
    "    out = ks.layers.Dense(num_nuerons[1], activation='relu')(out)\n",
    "    out = ks.layers.Dropout(dp)(out)\n",
    "    out = ks.layers.Dense(num_nuerons[2], activation='relu')(out)\n",
    "    out = ks.layers.Dense(6, activation='softmax')(out)\n",
    "    model = ks.Model(model_in, out)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy']) # rmsprop/adam\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "861ac9a9",
   "metadata": {
    "tags": [
     "remove_output"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n",
      "695/695 - 4s - loss: 0.5441 - accuracy: 0.8276 - val_loss: 0.2704 - val_accuracy: 0.9099 - 4s/epoch - 5ms/step\n",
      "Epoch 2/10000\n",
      "695/695 - 4s - loss: 0.1956 - accuracy: 0.9441 - val_loss: 0.2496 - val_accuracy: 0.9206 - 4s/epoch - 6ms/step\n",
      "Epoch 3/10000\n",
      "695/695 - 4s - loss: 0.1485 - accuracy: 0.9556 - val_loss: 0.2424 - val_accuracy: 0.9225 - 4s/epoch - 6ms/step\n",
      "Epoch 4/10000\n",
      "695/695 - 3s - loss: 0.1199 - accuracy: 0.9637 - val_loss: 0.2925 - val_accuracy: 0.9159 - 3s/epoch - 5ms/step\n",
      "Epoch 5/10000\n",
      "695/695 - 4s - loss: 0.1012 - accuracy: 0.9697 - val_loss: 0.2712 - val_accuracy: 0.9231 - 4s/epoch - 5ms/step\n",
      "Epoch 6/10000\n",
      "695/695 - 4s - loss: 0.0925 - accuracy: 0.9711 - val_loss: 0.2655 - val_accuracy: 0.9294 - 4s/epoch - 5ms/step\n",
      "Epoch 7/10000\n",
      "695/695 - 4s - loss: 0.0783 - accuracy: 0.9754 - val_loss: 0.2870 - val_accuracy: 0.9231 - 4s/epoch - 5ms/step\n",
      "Epoch 8/10000\n",
      "695/695 - 4s - loss: 0.0733 - accuracy: 0.9777 - val_loss: 0.3084 - val_accuracy: 0.9263 - 4s/epoch - 6ms/step\n",
      "Epoch 9/10000\n",
      "695/695 - 3s - loss: 0.0594 - accuracy: 0.9809 - val_loss: 0.3363 - val_accuracy: 0.9263 - 3s/epoch - 5ms/step\n",
      "Epoch 10/10000\n",
      "695/695 - 3s - loss: 0.0578 - accuracy: 0.9813 - val_loss: 0.3189 - val_accuracy: 0.9269 - 3s/epoch - 5ms/step\n",
      "Epoch 11/10000\n",
      "695/695 - 3s - loss: 0.0587 - accuracy: 0.9806 - val_loss: 0.3395 - val_accuracy: 0.9272 - 3s/epoch - 5ms/step\n",
      "Epoch 12/10000\n",
      "695/695 - 4s - loss: 0.0490 - accuracy: 0.9843 - val_loss: 0.3505 - val_accuracy: 0.9291 - 4s/epoch - 5ms/step\n",
      "Epoch 13/10000\n",
      "695/695 - 4s - loss: 0.0476 - accuracy: 0.9845 - val_loss: 0.3842 - val_accuracy: 0.9247 - 4s/epoch - 5ms/step\n",
      "Epoch 14/10000\n",
      "695/695 - 4s - loss: 0.0393 - accuracy: 0.9867 - val_loss: 0.3936 - val_accuracy: 0.9263 - 4s/epoch - 6ms/step\n",
      "Epoch 15/10000\n",
      "695/695 - 4s - loss: 0.0431 - accuracy: 0.9855 - val_loss: 0.3849 - val_accuracy: 0.9256 - 4s/epoch - 5ms/step\n",
      "Epoch 16/10000\n",
      "695/695 - 3s - loss: 0.0436 - accuracy: 0.9860 - val_loss: 0.4015 - val_accuracy: 0.9241 - 3s/epoch - 5ms/step\n",
      "Epoch 17/10000\n",
      "695/695 - 4s - loss: 0.0393 - accuracy: 0.9869 - val_loss: 0.4132 - val_accuracy: 0.9275 - 4s/epoch - 5ms/step\n",
      "Epoch 18/10000\n",
      "695/695 - 3s - loss: 0.0312 - accuracy: 0.9891 - val_loss: 0.4415 - val_accuracy: 0.9250 - 3s/epoch - 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "INPUT_SHAPE = X_train_cnn.shape[1]\n",
    "model = create_model_cnn()\n",
    "\n",
    "# Fit model on training data\n",
    "history = model.fit(\n",
    "    X_train_cnn,\n",
    "    y_train_cnn,\n",
    "    callbacks=[es_cnn],\n",
    "    epochs=10000,\n",
    "    shuffle=True,\n",
    "    validation_data=(X_valid_cnn, y_valid_cnn),\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab007f2",
   "metadata": {},
   "source": [
    "### Evaluate Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a0f9d06",
   "metadata": {},
   "source": [
    "**Plotting training and validation accuracy:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "95cb6686",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_accuracy(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785c9ecf",
   "metadata": {},
   "source": [
    "**Classification Report on validation data:**\n",
    "\n",
    "(validation data was used by the model for estimating performance, but model was not trained on it!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "78e37182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.95      0.96      1079\n",
      "           1       0.87      0.90      0.89      1509\n",
      "           2       0.94      0.95      0.94       648\n",
      "           3       0.74      0.73      0.73       758\n",
      "           4       0.92      0.90      0.91       981\n",
      "           5       0.93      0.93      0.93      1374\n",
      "\n",
      "    accuracy                           0.90      6349\n",
      "   macro avg       0.89      0.89      0.89      6349\n",
      "weighted avg       0.90      0.90      0.90      6349\n",
      "\n",
      "Accuracy on test: 89.84\n"
     ]
    }
   ],
   "source": [
    "preds = model.predict(X_test_cnn, verbose=0)\n",
    "# Classification report\n",
    "print(classification_report(y_test_cnn.argmax(axis=1), preds.argmax(axis=1)))\n",
    "_, accuracy = model.evaluate(X_test_cnn, y_test_cnn, verbose=0)\n",
    "print('Accuracy on test: %.2f' % (accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3fc1ce5",
   "metadata": {},
   "source": [
    "Looks like we do much worse here, so we're not gonna include it in one of our predictions :(\n",
    "\n",
    "We think it's because our CNN model does very poorly on chocolate, but pretty good on all other categories. So what happens is this model believes our CNN prediction as generally it's a good one, and therefore performs now poorly on chocolate as well.\n",
    "\n",
    "We have ideas our to improve this:\n",
    "- Perform CV with this feature as well.\n",
    "- Engineer this feature in another way - maybe ignore the CNNs prediction for chocolate, and create less features that indicate whether our CNN thinks the product belongs to some other category (but only categories it performs well on).\n",
    "- Improve our CNN, of course.\n",
    "- Engineer additional features for chocolate that maybe will help balance the CNNs predictions.\n",
    "\n",
    "We just don't have time to do these, but we wanted to mention them."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f98bf38c",
   "metadata": {},
   "source": [
    "<img src=\"./images/meme4.png\"\n",
    "     alt=\"another meme\"\n",
    "     width=\"400\"\n",
    "     height=\"400\"\n",
    "     style=\"float: left; margin-right: 10px;\" />"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tau-dsapps-3.8.9",
   "language": "python",
   "name": "tau-dsapps-3.8.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
